{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c3539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from CNN_model import CNN\n",
    "from load_data import DatasetFromHdf5\n",
    "from utils import ts_to_np,np_to_ts,batch_psnr,plot_loss_save,plot_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42f376",
   "metadata": {},
   "source": [
    "check if GPU can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9bd10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs 1\n"
     ]
    }
   ],
   "source": [
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f973e44d",
   "metadata": {},
   "source": [
    "Parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad1cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize=20\n",
    "num_images=5000\n",
    "epochs=200\n",
    "image_size=32\n",
    "print_every=50\n",
    "lr=0.001\n",
    "model_path='./model_dir'\n",
    "iters=[]\n",
    "y_loss=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd0ffe",
   "metadata": {},
   "source": [
    "Load training dataseta and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c06b6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pengyang\\pytorch\\DLGI\\DNN\\load_data.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  hf = h5py.File(file_path)\n"
     ]
    }
   ],
   "source": [
    "train_set = DatasetFromHdf5(\"./dataset/train_mnist.h5\")\n",
    "test_set = DatasetFromHdf5(\"./dataset/test_mnist.h5\")\n",
    "training_data_loader = DataLoader(dataset=train_set,batch_size=batchSize, shuffle=True)\n",
    "testing_data_loader = DataLoader(dataset=test_set,batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6362c8a",
   "metadata": {},
   "source": [
    "Initialize the model and define the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5fa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN()\n",
    "criterion=nn.MSELoss()\n",
    "if torch.cuda.is_available:\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "    \n",
    "optimizer=optim.Adam(model.parameters(),lr=lr)\n",
    "device=torch.device('cuda:0' if GPU else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b0d13",
   "metadata": {},
   "source": [
    "Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b9c9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1][50/250] loss: 0.0009557310 PSNR_train: 14.7848\n",
      "[epoch 1][100/250] loss: 0.0007288351 PSNR_train: 15.6743\n",
      "[epoch 1][150/250] loss: 0.0005371521 PSNR_train: 16.9614\n",
      "[epoch 1][200/250] loss: 0.0005187196 PSNR_train: 17.7509\n",
      "[epoch 1][250/250] loss: 0.0004837354 PSNR_train: 17.9244\n",
      "\n",
      "[epoch 1] PSNR_test: 18.3237\n",
      "[epoch 2][50/250] loss: 0.0003527261 PSNR_train: 19.1225\n",
      "[epoch 2][100/250] loss: 0.0003515625 PSNR_train: 19.2958\n",
      "[epoch 2][150/250] loss: 0.0003929225 PSNR_train: 19.6655\n",
      "[epoch 2][200/250] loss: 0.0003030020 PSNR_train: 19.7382\n",
      "[epoch 2][250/250] loss: 0.0002779115 PSNR_train: 20.4902\n",
      "\n",
      "[epoch 2] PSNR_test: 20.0033\n",
      "[epoch 3][50/250] loss: 0.0002679197 PSNR_train: 20.1715\n",
      "[epoch 3][100/250] loss: 0.0002457357 PSNR_train: 21.3983\n",
      "[epoch 3][150/250] loss: 0.0002747801 PSNR_train: 19.9051\n",
      "[epoch 3][200/250] loss: 0.0002352301 PSNR_train: 21.2012\n",
      "[epoch 3][250/250] loss: 0.0002011883 PSNR_train: 21.8288\n",
      "\n",
      "[epoch 3] PSNR_test: 20.9230\n",
      "[epoch 4][50/250] loss: 0.0002071393 PSNR_train: 21.7898\n",
      "[epoch 4][100/250] loss: 0.0001991326 PSNR_train: 22.1092\n",
      "[epoch 4][150/250] loss: 0.0001805298 PSNR_train: 22.3345\n",
      "[epoch 4][200/250] loss: 0.0001862443 PSNR_train: 21.8691\n",
      "[epoch 4][250/250] loss: 0.0002706067 PSNR_train: 20.7106\n",
      "\n",
      "[epoch 4] PSNR_test: 21.4714\n",
      "[epoch 5][50/250] loss: 0.0001510519 PSNR_train: 22.7435\n",
      "[epoch 5][100/250] loss: 0.0001784878 PSNR_train: 22.0536\n",
      "[epoch 5][150/250] loss: 0.0001886285 PSNR_train: 22.2749\n",
      "[epoch 5][200/250] loss: 0.0001868959 PSNR_train: 22.3413\n",
      "[epoch 5][250/250] loss: 0.0001804833 PSNR_train: 22.3659\n",
      "\n",
      "[epoch 5] PSNR_test: 21.7760\n",
      "[epoch 6][50/250] loss: 0.0001910805 PSNR_train: 21.9069\n",
      "[epoch 6][100/250] loss: 0.0001886292 PSNR_train: 21.9848\n",
      "[epoch 6][150/250] loss: 0.0001568208 PSNR_train: 23.3637\n",
      "[epoch 6][200/250] loss: 0.0001596840 PSNR_train: 23.0774\n",
      "[epoch 6][250/250] loss: 0.0001593419 PSNR_train: 22.7146\n",
      "\n",
      "[epoch 6] PSNR_test: 22.2032\n",
      "[epoch 7][50/250] loss: 0.0001090306 PSNR_train: 24.5989\n",
      "[epoch 7][100/250] loss: 0.0001452144 PSNR_train: 23.2965\n",
      "[epoch 7][150/250] loss: 0.0001874346 PSNR_train: 22.2796\n",
      "[epoch 7][200/250] loss: 0.0001457408 PSNR_train: 23.2064\n",
      "[epoch 7][250/250] loss: 0.0001135595 PSNR_train: 24.3307\n",
      "\n",
      "[epoch 7] PSNR_test: 22.3301\n",
      "[epoch 8][50/250] loss: 0.0001268916 PSNR_train: 23.4481\n",
      "[epoch 8][100/250] loss: 0.0001169936 PSNR_train: 23.7841\n",
      "[epoch 8][150/250] loss: 0.0001320095 PSNR_train: 24.2626\n",
      "[epoch 8][200/250] loss: 0.0001549050 PSNR_train: 22.8421\n",
      "[epoch 8][250/250] loss: 0.0001250542 PSNR_train: 23.8484\n",
      "\n",
      "[epoch 8] PSNR_test: 22.6306\n",
      "[epoch 9][50/250] loss: 0.0001358708 PSNR_train: 23.2335\n",
      "[epoch 9][100/250] loss: 0.0001358253 PSNR_train: 23.7751\n",
      "[epoch 9][150/250] loss: 0.0001407392 PSNR_train: 23.4858\n",
      "[epoch 9][200/250] loss: 0.0001243766 PSNR_train: 24.0100\n",
      "[epoch 9][250/250] loss: 0.0001247591 PSNR_train: 23.9990\n",
      "\n",
      "[epoch 9] PSNR_test: 22.6908\n",
      "[epoch 10][50/250] loss: 0.0001241636 PSNR_train: 23.8259\n",
      "[epoch 10][100/250] loss: 0.0000976625 PSNR_train: 24.6072\n",
      "[epoch 10][150/250] loss: 0.0001232379 PSNR_train: 23.8242\n",
      "[epoch 10][200/250] loss: 0.0001204146 PSNR_train: 23.5579\n",
      "[epoch 10][250/250] loss: 0.0001118661 PSNR_train: 24.3728\n",
      "\n",
      "[epoch 10] PSNR_test: 22.7686\n",
      "[epoch 11][50/250] loss: 0.0001249839 PSNR_train: 23.4239\n",
      "[epoch 11][100/250] loss: 0.0001326114 PSNR_train: 23.6396\n",
      "[epoch 11][150/250] loss: 0.0001084734 PSNR_train: 24.5712\n",
      "[epoch 11][200/250] loss: 0.0000913926 PSNR_train: 24.8977\n",
      "[epoch 11][250/250] loss: 0.0001173424 PSNR_train: 24.0508\n",
      "\n",
      "[epoch 11] PSNR_test: 22.9338\n",
      "[epoch 12][50/250] loss: 0.0001077127 PSNR_train: 24.5508\n",
      "[epoch 12][100/250] loss: 0.0001089818 PSNR_train: 24.4042\n",
      "[epoch 12][150/250] loss: 0.0000872160 PSNR_train: 25.1589\n",
      "[epoch 12][200/250] loss: 0.0001373209 PSNR_train: 23.1357\n",
      "[epoch 12][250/250] loss: 0.0001117565 PSNR_train: 24.5069\n",
      "\n",
      "[epoch 12] PSNR_test: 22.9584\n",
      "[epoch 13][50/250] loss: 0.0001218731 PSNR_train: 23.5409\n",
      "[epoch 13][100/250] loss: 0.0001025224 PSNR_train: 24.6729\n",
      "[epoch 13][150/250] loss: 0.0001367020 PSNR_train: 23.5226\n",
      "[epoch 13][200/250] loss: 0.0001046318 PSNR_train: 24.4083\n",
      "[epoch 13][250/250] loss: 0.0001150662 PSNR_train: 24.4811\n",
      "\n",
      "[epoch 13] PSNR_test: 22.9613\n",
      "[epoch 14][50/250] loss: 0.0001413508 PSNR_train: 23.5421\n",
      "[epoch 14][100/250] loss: 0.0000873628 PSNR_train: 25.1004\n",
      "[epoch 14][150/250] loss: 0.0001020619 PSNR_train: 25.4070\n",
      "[epoch 14][200/250] loss: 0.0001211819 PSNR_train: 24.0152\n",
      "[epoch 14][250/250] loss: 0.0001055393 PSNR_train: 24.4860\n",
      "\n",
      "[epoch 14] PSNR_test: 22.8122\n",
      "[epoch 15][50/250] loss: 0.0000867414 PSNR_train: 25.0406\n",
      "[epoch 15][100/250] loss: 0.0000888598 PSNR_train: 25.0466\n",
      "[epoch 15][150/250] loss: 0.0001168742 PSNR_train: 24.5469\n",
      "[epoch 15][200/250] loss: 0.0000984024 PSNR_train: 24.7048\n",
      "[epoch 15][250/250] loss: 0.0001411688 PSNR_train: 23.2002\n",
      "\n",
      "[epoch 15] PSNR_test: 23.1309\n",
      "[epoch 16][50/250] loss: 0.0001111581 PSNR_train: 24.3674\n",
      "[epoch 16][100/250] loss: 0.0000895278 PSNR_train: 25.1951\n",
      "[epoch 16][150/250] loss: 0.0000855657 PSNR_train: 25.7778\n",
      "[epoch 16][200/250] loss: 0.0001063548 PSNR_train: 24.3948\n",
      "[epoch 16][250/250] loss: 0.0001141560 PSNR_train: 24.7427\n",
      "\n",
      "[epoch 16] PSNR_test: 23.0349\n",
      "[epoch 17][50/250] loss: 0.0000798715 PSNR_train: 25.8393\n",
      "[epoch 17][100/250] loss: 0.0000817793 PSNR_train: 25.5272\n",
      "[epoch 17][150/250] loss: 0.0001268452 PSNR_train: 24.7160\n",
      "[epoch 17][200/250] loss: 0.0000945128 PSNR_train: 25.0241\n",
      "[epoch 17][250/250] loss: 0.0000892364 PSNR_train: 25.2015\n",
      "\n",
      "[epoch 17] PSNR_test: 23.1309\n",
      "[epoch 18][50/250] loss: 0.0001003802 PSNR_train: 24.3785\n",
      "[epoch 18][100/250] loss: 0.0000868480 PSNR_train: 25.1689\n",
      "[epoch 18][150/250] loss: 0.0001266926 PSNR_train: 24.0776\n",
      "[epoch 18][200/250] loss: 0.0000991290 PSNR_train: 24.9335\n",
      "[epoch 18][250/250] loss: 0.0000971794 PSNR_train: 24.6470\n",
      "\n",
      "[epoch 18] PSNR_test: 23.2036\n",
      "[epoch 19][50/250] loss: 0.0000859837 PSNR_train: 25.5690\n",
      "[epoch 19][100/250] loss: 0.0000899950 PSNR_train: 24.9825\n",
      "[epoch 19][150/250] loss: 0.0000997163 PSNR_train: 24.5863\n",
      "[epoch 19][200/250] loss: 0.0000822893 PSNR_train: 25.3567\n",
      "[epoch 19][250/250] loss: 0.0001107040 PSNR_train: 24.2413\n",
      "\n",
      "[epoch 19] PSNR_test: 23.2232\n",
      "[epoch 20][50/250] loss: 0.0001020490 PSNR_train: 24.6507\n",
      "[epoch 20][100/250] loss: 0.0000898863 PSNR_train: 24.6960\n",
      "[epoch 20][150/250] loss: 0.0000755530 PSNR_train: 25.4537\n",
      "[epoch 20][200/250] loss: 0.0000833429 PSNR_train: 25.2966\n",
      "[epoch 20][250/250] loss: 0.0000993065 PSNR_train: 24.6370\n",
      "\n",
      "[epoch 20] PSNR_test: 23.1780\n",
      "[epoch 21][50/250] loss: 0.0000801262 PSNR_train: 25.4760\n",
      "[epoch 21][100/250] loss: 0.0000999870 PSNR_train: 25.0901\n",
      "[epoch 21][150/250] loss: 0.0001000626 PSNR_train: 24.6104\n",
      "[epoch 21][200/250] loss: 0.0001208687 PSNR_train: 24.0323\n",
      "[epoch 21][250/250] loss: 0.0000738720 PSNR_train: 25.8264\n",
      "\n",
      "[epoch 21] PSNR_test: 23.2117\n",
      "[epoch 22][50/250] loss: 0.0000945126 PSNR_train: 25.2824\n",
      "[epoch 22][100/250] loss: 0.0000801841 PSNR_train: 25.5545\n",
      "[epoch 22][150/250] loss: 0.0000999249 PSNR_train: 24.5680\n",
      "[epoch 22][200/250] loss: 0.0000855538 PSNR_train: 25.6366\n",
      "[epoch 22][250/250] loss: 0.0000921206 PSNR_train: 24.9143\n",
      "\n",
      "[epoch 22] PSNR_test: 23.1764\n",
      "[epoch 23][50/250] loss: 0.0000847776 PSNR_train: 25.1807\n",
      "[epoch 23][100/250] loss: 0.0001370665 PSNR_train: 23.8944\n",
      "[epoch 23][150/250] loss: 0.0000884643 PSNR_train: 25.7850\n",
      "[epoch 23][200/250] loss: 0.0001073239 PSNR_train: 24.3405\n",
      "[epoch 23][250/250] loss: 0.0000973300 PSNR_train: 24.7722\n",
      "\n",
      "[epoch 23] PSNR_test: 23.2318\n",
      "[epoch 24][50/250] loss: 0.0000901694 PSNR_train: 25.2515\n",
      "[epoch 24][100/250] loss: 0.0000725630 PSNR_train: 25.7383\n",
      "[epoch 24][150/250] loss: 0.0001004292 PSNR_train: 24.7001\n",
      "[epoch 24][200/250] loss: 0.0000867833 PSNR_train: 25.0987\n",
      "[epoch 24][250/250] loss: 0.0000998187 PSNR_train: 24.6263\n",
      "\n",
      "[epoch 24] PSNR_test: 23.3280\n",
      "[epoch 25][50/250] loss: 0.0001042289 PSNR_train: 24.5834\n",
      "[epoch 25][100/250] loss: 0.0000695729 PSNR_train: 27.0137\n",
      "[epoch 25][150/250] loss: 0.0000763803 PSNR_train: 25.9190\n",
      "[epoch 25][200/250] loss: 0.0000768208 PSNR_train: 26.0014\n",
      "[epoch 25][250/250] loss: 0.0000746804 PSNR_train: 26.1222\n",
      "\n",
      "[epoch 25] PSNR_test: 22.7779\n",
      "[epoch 26][50/250] loss: 0.0000654806 PSNR_train: 26.7063\n",
      "[epoch 26][100/250] loss: 0.0000948490 PSNR_train: 24.9785\n",
      "[epoch 26][150/250] loss: 0.0000770146 PSNR_train: 25.7642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 26][200/250] loss: 0.0000823527 PSNR_train: 25.4088\n",
      "[epoch 26][250/250] loss: 0.0000869674 PSNR_train: 24.9663\n",
      "\n",
      "[epoch 26] PSNR_test: 23.3005\n",
      "[epoch 27][50/250] loss: 0.0000734528 PSNR_train: 26.5759\n",
      "[epoch 27][100/250] loss: 0.0000791140 PSNR_train: 25.7355\n",
      "[epoch 27][150/250] loss: 0.0000843463 PSNR_train: 25.3854\n",
      "[epoch 27][200/250] loss: 0.0000753687 PSNR_train: 25.8331\n",
      "[epoch 27][250/250] loss: 0.0000875357 PSNR_train: 25.1580\n",
      "\n",
      "[epoch 27] PSNR_test: 23.2905\n",
      "[epoch 28][50/250] loss: 0.0000843371 PSNR_train: 25.4300\n",
      "[epoch 28][100/250] loss: 0.0000749761 PSNR_train: 25.9523\n",
      "[epoch 28][150/250] loss: 0.0000646611 PSNR_train: 26.5204\n",
      "[epoch 28][200/250] loss: 0.0000712416 PSNR_train: 25.8971\n",
      "[epoch 28][250/250] loss: 0.0000725075 PSNR_train: 26.0152\n",
      "\n",
      "[epoch 28] PSNR_test: 23.1809\n",
      "[epoch 29][50/250] loss: 0.0000661934 PSNR_train: 26.2762\n",
      "[epoch 29][100/250] loss: 0.0000743809 PSNR_train: 26.0833\n",
      "[epoch 29][150/250] loss: 0.0000579498 PSNR_train: 26.8204\n",
      "[epoch 29][200/250] loss: 0.0000838908 PSNR_train: 25.5659\n",
      "[epoch 29][250/250] loss: 0.0000948799 PSNR_train: 24.8158\n",
      "\n",
      "[epoch 29] PSNR_test: 23.3584\n",
      "[epoch 30][50/250] loss: 0.0000730033 PSNR_train: 26.4072\n",
      "[epoch 30][100/250] loss: 0.0000910907 PSNR_train: 25.2445\n",
      "[epoch 30][150/250] loss: 0.0000751064 PSNR_train: 25.5654\n",
      "[epoch 30][200/250] loss: 0.0000897659 PSNR_train: 25.9712\n",
      "[epoch 30][250/250] loss: 0.0000692841 PSNR_train: 26.3523\n",
      "\n",
      "[epoch 30] PSNR_test: 23.2402\n",
      "[epoch 31][50/250] loss: 0.0000555770 PSNR_train: 27.2025\n",
      "[epoch 31][100/250] loss: 0.0000694947 PSNR_train: 26.3401\n",
      "[epoch 31][150/250] loss: 0.0000642169 PSNR_train: 26.5595\n",
      "[epoch 31][200/250] loss: 0.0000874905 PSNR_train: 25.4271\n",
      "[epoch 31][250/250] loss: 0.0000822694 PSNR_train: 25.5906\n",
      "\n",
      "[epoch 31] PSNR_test: 23.2536\n",
      "[epoch 32][50/250] loss: 0.0000648654 PSNR_train: 26.4904\n",
      "[epoch 32][100/250] loss: 0.0000820551 PSNR_train: 25.6018\n",
      "[epoch 32][150/250] loss: 0.0000552679 PSNR_train: 26.7999\n",
      "[epoch 32][200/250] loss: 0.0000487045 PSNR_train: 27.5840\n",
      "[epoch 32][250/250] loss: 0.0000644370 PSNR_train: 26.1079\n",
      "\n",
      "[epoch 32] PSNR_test: 23.3700\n",
      "[epoch 33][50/250] loss: 0.0000734546 PSNR_train: 26.0568\n",
      "[epoch 33][100/250] loss: 0.0000979745 PSNR_train: 24.6725\n",
      "[epoch 33][150/250] loss: 0.0000726267 PSNR_train: 25.9362\n",
      "[epoch 33][200/250] loss: 0.0000757435 PSNR_train: 25.9707\n",
      "[epoch 33][250/250] loss: 0.0000505513 PSNR_train: 27.5048\n",
      "\n",
      "[epoch 33] PSNR_test: 23.3521\n",
      "[epoch 34][50/250] loss: 0.0000768559 PSNR_train: 25.8447\n",
      "[epoch 34][100/250] loss: 0.0000911724 PSNR_train: 25.2950\n",
      "[epoch 34][150/250] loss: 0.0000628163 PSNR_train: 26.4400\n",
      "[epoch 34][200/250] loss: 0.0000986198 PSNR_train: 25.3021\n",
      "[epoch 34][250/250] loss: 0.0000690703 PSNR_train: 26.0529\n",
      "\n",
      "[epoch 34] PSNR_test: 23.2408\n",
      "[epoch 35][50/250] loss: 0.0000608057 PSNR_train: 26.5284\n",
      "[epoch 35][100/250] loss: 0.0000729432 PSNR_train: 26.0876\n",
      "[epoch 35][150/250] loss: 0.0000791009 PSNR_train: 25.7791\n",
      "[epoch 35][200/250] loss: 0.0000743138 PSNR_train: 26.1663\n",
      "[epoch 35][250/250] loss: 0.0000704054 PSNR_train: 26.1527\n",
      "\n",
      "[epoch 35] PSNR_test: 23.3407\n",
      "[epoch 36][50/250] loss: 0.0000657844 PSNR_train: 26.7235\n",
      "[epoch 36][100/250] loss: 0.0000877389 PSNR_train: 25.5858\n",
      "[epoch 36][150/250] loss: 0.0000818664 PSNR_train: 26.1825\n",
      "[epoch 36][200/250] loss: 0.0000632679 PSNR_train: 26.7594\n",
      "[epoch 36][250/250] loss: 0.0000810280 PSNR_train: 25.5147\n",
      "\n",
      "[epoch 36] PSNR_test: 23.2051\n",
      "[epoch 37][50/250] loss: 0.0000606902 PSNR_train: 26.5512\n",
      "[epoch 37][100/250] loss: 0.0000524102 PSNR_train: 26.9375\n",
      "[epoch 37][150/250] loss: 0.0000547326 PSNR_train: 27.1697\n",
      "[epoch 37][200/250] loss: 0.0000659443 PSNR_train: 25.9516\n",
      "[epoch 37][250/250] loss: 0.0000683677 PSNR_train: 26.1531\n",
      "\n",
      "[epoch 37] PSNR_test: 23.2071\n",
      "[epoch 38][50/250] loss: 0.0000748565 PSNR_train: 26.3686\n",
      "[epoch 38][100/250] loss: 0.0000582725 PSNR_train: 26.5546\n",
      "[epoch 38][150/250] loss: 0.0000755115 PSNR_train: 25.8209\n",
      "[epoch 38][200/250] loss: 0.0000651129 PSNR_train: 26.4704\n",
      "[epoch 38][250/250] loss: 0.0000637524 PSNR_train: 26.6604\n",
      "\n",
      "[epoch 38] PSNR_test: 23.2815\n",
      "[epoch 39][50/250] loss: 0.0000677855 PSNR_train: 26.3623\n",
      "[epoch 39][100/250] loss: 0.0000713104 PSNR_train: 26.4005\n",
      "[epoch 39][150/250] loss: 0.0000803317 PSNR_train: 25.4357\n",
      "[epoch 39][200/250] loss: 0.0000655357 PSNR_train: 26.2934\n",
      "[epoch 39][250/250] loss: 0.0000665664 PSNR_train: 26.1942\n",
      "\n",
      "[epoch 39] PSNR_test: 23.2447\n",
      "[epoch 40][50/250] loss: 0.0000746273 PSNR_train: 26.1130\n",
      "[epoch 40][100/250] loss: 0.0000878731 PSNR_train: 25.4061\n",
      "[epoch 40][150/250] loss: 0.0000650064 PSNR_train: 26.3456\n",
      "[epoch 40][200/250] loss: 0.0000735767 PSNR_train: 25.7676\n",
      "[epoch 40][250/250] loss: 0.0000638359 PSNR_train: 26.4238\n",
      "\n",
      "[epoch 40] PSNR_test: 23.1880\n",
      "[epoch 41][50/250] loss: 0.0000621965 PSNR_train: 26.6019\n",
      "[epoch 41][100/250] loss: 0.0000715169 PSNR_train: 25.7735\n",
      "[epoch 41][150/250] loss: 0.0000622052 PSNR_train: 27.1587\n",
      "[epoch 41][200/250] loss: 0.0000608554 PSNR_train: 26.7455\n",
      "[epoch 41][250/250] loss: 0.0000683163 PSNR_train: 26.0922\n",
      "\n",
      "[epoch 41] PSNR_test: 23.3724\n",
      "[epoch 42][50/250] loss: 0.0000556497 PSNR_train: 27.0785\n",
      "[epoch 42][100/250] loss: 0.0000447670 PSNR_train: 28.0443\n",
      "[epoch 42][150/250] loss: 0.0000579380 PSNR_train: 26.8710\n",
      "[epoch 42][200/250] loss: 0.0000609756 PSNR_train: 26.3904\n",
      "[epoch 42][250/250] loss: 0.0000690446 PSNR_train: 26.5071\n",
      "\n",
      "[epoch 42] PSNR_test: 23.2864\n",
      "[epoch 43][50/250] loss: 0.0000653970 PSNR_train: 26.2862\n",
      "[epoch 43][100/250] loss: 0.0000591647 PSNR_train: 27.1164\n",
      "[epoch 43][150/250] loss: 0.0000685723 PSNR_train: 26.1545\n",
      "[epoch 43][200/250] loss: 0.0000698164 PSNR_train: 26.1003\n",
      "[epoch 43][250/250] loss: 0.0000630834 PSNR_train: 26.4863\n",
      "\n",
      "[epoch 43] PSNR_test: 23.3183\n",
      "[epoch 44][50/250] loss: 0.0000737154 PSNR_train: 26.1107\n",
      "[epoch 44][100/250] loss: 0.0000661543 PSNR_train: 26.3952\n",
      "[epoch 44][150/250] loss: 0.0000721138 PSNR_train: 26.3056\n",
      "[epoch 44][200/250] loss: 0.0000619129 PSNR_train: 26.3704\n",
      "[epoch 44][250/250] loss: 0.0000609812 PSNR_train: 26.7909\n",
      "\n",
      "[epoch 44] PSNR_test: 23.3702\n",
      "[epoch 45][50/250] loss: 0.0000669727 PSNR_train: 26.1658\n",
      "[epoch 45][100/250] loss: 0.0000564440 PSNR_train: 26.8320\n",
      "[epoch 45][150/250] loss: 0.0000670445 PSNR_train: 26.2162\n",
      "[epoch 45][200/250] loss: 0.0000542129 PSNR_train: 27.0769\n",
      "[epoch 45][250/250] loss: 0.0000633918 PSNR_train: 26.5033\n",
      "\n",
      "[epoch 45] PSNR_test: 23.3206\n",
      "[epoch 46][50/250] loss: 0.0000582741 PSNR_train: 26.8460\n",
      "[epoch 46][100/250] loss: 0.0000654303 PSNR_train: 26.2438\n",
      "[epoch 46][150/250] loss: 0.0000701151 PSNR_train: 26.5060\n",
      "[epoch 46][200/250] loss: 0.0000558455 PSNR_train: 26.8710\n",
      "[epoch 46][250/250] loss: 0.0000759462 PSNR_train: 26.1772\n",
      "\n",
      "[epoch 46] PSNR_test: 23.3620\n",
      "[epoch 47][50/250] loss: 0.0000665264 PSNR_train: 26.5791\n",
      "[epoch 47][100/250] loss: 0.0000463115 PSNR_train: 27.7965\n",
      "[epoch 47][150/250] loss: 0.0000590101 PSNR_train: 26.8130\n",
      "[epoch 47][200/250] loss: 0.0000712132 PSNR_train: 26.2549\n",
      "[epoch 47][250/250] loss: 0.0000652858 PSNR_train: 26.2747\n",
      "\n",
      "[epoch 47] PSNR_test: 23.2762\n",
      "[epoch 48][50/250] loss: 0.0000657140 PSNR_train: 27.0762\n",
      "[epoch 48][100/250] loss: 0.0000577163 PSNR_train: 26.8626\n",
      "[epoch 48][150/250] loss: 0.0000499201 PSNR_train: 27.5643\n",
      "[epoch 48][200/250] loss: 0.0000612316 PSNR_train: 26.4864\n",
      "[epoch 48][250/250] loss: 0.0000683169 PSNR_train: 25.9823\n",
      "\n",
      "[epoch 48] PSNR_test: 23.3179\n",
      "[epoch 49][50/250] loss: 0.0000552241 PSNR_train: 27.1791\n",
      "[epoch 49][100/250] loss: 0.0000548325 PSNR_train: 27.1456\n",
      "[epoch 49][150/250] loss: 0.0000737627 PSNR_train: 26.1898\n",
      "[epoch 49][200/250] loss: 0.0000652620 PSNR_train: 26.2374\n",
      "[epoch 49][250/250] loss: 0.0000548426 PSNR_train: 27.0262\n",
      "\n",
      "[epoch 49] PSNR_test: 23.3721\n",
      "[epoch 50][50/250] loss: 0.0000608828 PSNR_train: 26.6297\n",
      "[epoch 50][100/250] loss: 0.0000586639 PSNR_train: 26.7721\n",
      "[epoch 50][150/250] loss: 0.0000515034 PSNR_train: 27.2351\n",
      "[epoch 50][200/250] loss: 0.0000541204 PSNR_train: 27.0538\n",
      "[epoch 50][250/250] loss: 0.0000644119 PSNR_train: 26.4040\n",
      "\n",
      "[epoch 50] PSNR_test: 23.3217\n",
      "[epoch 51][50/250] loss: 0.0000531384 PSNR_train: 27.2403\n",
      "[epoch 51][100/250] loss: 0.0000535034 PSNR_train: 27.3049\n",
      "[epoch 51][150/250] loss: 0.0000421272 PSNR_train: 28.1777\n",
      "[epoch 51][200/250] loss: 0.0000523721 PSNR_train: 27.3624\n",
      "[epoch 51][250/250] loss: 0.0000458565 PSNR_train: 27.6847\n",
      "\n",
      "[epoch 51] PSNR_test: 23.3886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 52][50/250] loss: 0.0000765002 PSNR_train: 26.3889\n",
      "[epoch 52][100/250] loss: 0.0000495129 PSNR_train: 27.3973\n",
      "[epoch 52][150/250] loss: 0.0000580627 PSNR_train: 27.2445\n",
      "[epoch 52][200/250] loss: 0.0000684496 PSNR_train: 26.2390\n",
      "[epoch 52][250/250] loss: 0.0000552159 PSNR_train: 27.1427\n",
      "\n",
      "[epoch 52] PSNR_test: 23.4542\n",
      "[epoch 53][50/250] loss: 0.0000562296 PSNR_train: 27.3409\n",
      "[epoch 53][100/250] loss: 0.0000590050 PSNR_train: 26.7163\n",
      "[epoch 53][150/250] loss: 0.0000588399 PSNR_train: 26.6177\n",
      "[epoch 53][200/250] loss: 0.0000565847 PSNR_train: 26.9148\n",
      "[epoch 53][250/250] loss: 0.0000575383 PSNR_train: 27.0044\n",
      "\n",
      "[epoch 53] PSNR_test: 23.3219\n",
      "[epoch 54][50/250] loss: 0.0000421123 PSNR_train: 28.0538\n",
      "[epoch 54][100/250] loss: 0.0000497838 PSNR_train: 27.5220\n",
      "[epoch 54][150/250] loss: 0.0000550207 PSNR_train: 27.2740\n",
      "[epoch 54][200/250] loss: 0.0000605436 PSNR_train: 27.0151\n",
      "[epoch 54][250/250] loss: 0.0000470051 PSNR_train: 27.5349\n",
      "\n",
      "[epoch 54] PSNR_test: 23.3266\n",
      "[epoch 55][50/250] loss: 0.0000468783 PSNR_train: 27.6138\n",
      "[epoch 55][100/250] loss: 0.0000493632 PSNR_train: 27.4420\n",
      "[epoch 55][150/250] loss: 0.0000616783 PSNR_train: 26.6048\n",
      "[epoch 55][200/250] loss: 0.0000485688 PSNR_train: 27.6928\n",
      "[epoch 55][250/250] loss: 0.0000535935 PSNR_train: 27.2467\n",
      "\n",
      "[epoch 55] PSNR_test: 23.0436\n",
      "[epoch 56][50/250] loss: 0.0000490243 PSNR_train: 27.5739\n",
      "[epoch 56][100/250] loss: 0.0000540351 PSNR_train: 27.0884\n",
      "[epoch 56][150/250] loss: 0.0000583109 PSNR_train: 26.7105\n",
      "[epoch 56][200/250] loss: 0.0000634401 PSNR_train: 26.4509\n",
      "[epoch 56][250/250] loss: 0.0000487717 PSNR_train: 27.3246\n",
      "\n",
      "[epoch 56] PSNR_test: 23.3747\n",
      "[epoch 57][50/250] loss: 0.0000515604 PSNR_train: 27.7118\n",
      "[epoch 57][100/250] loss: 0.0000483214 PSNR_train: 27.4374\n",
      "[epoch 57][150/250] loss: 0.0000491690 PSNR_train: 27.4265\n",
      "[epoch 57][200/250] loss: 0.0000427850 PSNR_train: 27.8612\n",
      "[epoch 57][250/250] loss: 0.0000510070 PSNR_train: 27.3827\n",
      "\n",
      "[epoch 57] PSNR_test: 23.3598\n",
      "[epoch 58][50/250] loss: 0.0000466155 PSNR_train: 27.8100\n",
      "[epoch 58][100/250] loss: 0.0000500684 PSNR_train: 27.3532\n",
      "[epoch 58][150/250] loss: 0.0000443965 PSNR_train: 27.9727\n",
      "[epoch 58][200/250] loss: 0.0000558338 PSNR_train: 27.3746\n",
      "[epoch 58][250/250] loss: 0.0000659104 PSNR_train: 26.2712\n",
      "\n",
      "[epoch 58] PSNR_test: 23.2850\n",
      "[epoch 59][50/250] loss: 0.0000451835 PSNR_train: 27.9301\n",
      "[epoch 59][100/250] loss: 0.0000585380 PSNR_train: 26.9994\n",
      "[epoch 59][150/250] loss: 0.0000471512 PSNR_train: 27.4794\n",
      "[epoch 59][200/250] loss: 0.0000585483 PSNR_train: 27.0954\n",
      "[epoch 59][250/250] loss: 0.0000555841 PSNR_train: 26.7889\n",
      "\n",
      "[epoch 59] PSNR_test: 23.3181\n",
      "[epoch 60][50/250] loss: 0.0000542234 PSNR_train: 27.2286\n",
      "[epoch 60][100/250] loss: 0.0000485550 PSNR_train: 27.6462\n",
      "[epoch 60][150/250] loss: 0.0000478786 PSNR_train: 27.5497\n",
      "[epoch 60][200/250] loss: 0.0000476309 PSNR_train: 27.4474\n",
      "[epoch 60][250/250] loss: 0.0000443973 PSNR_train: 28.0251\n",
      "\n",
      "[epoch 60] PSNR_test: 23.3203\n",
      "[epoch 61][50/250] loss: 0.0000483738 PSNR_train: 27.4468\n",
      "[epoch 61][100/250] loss: 0.0000524740 PSNR_train: 27.6029\n",
      "[epoch 61][150/250] loss: 0.0000511124 PSNR_train: 27.0982\n",
      "[epoch 61][200/250] loss: 0.0000555299 PSNR_train: 26.8365\n",
      "[epoch 61][250/250] loss: 0.0000666551 PSNR_train: 26.2584\n",
      "\n",
      "[epoch 61] PSNR_test: 23.2571\n",
      "[epoch 62][50/250] loss: 0.0000616206 PSNR_train: 26.8075\n",
      "[epoch 62][100/250] loss: 0.0000407271 PSNR_train: 28.2067\n",
      "[epoch 62][150/250] loss: 0.0000500779 PSNR_train: 27.2792\n",
      "[epoch 62][200/250] loss: 0.0000570164 PSNR_train: 26.7602\n",
      "[epoch 62][250/250] loss: 0.0000484500 PSNR_train: 27.4808\n",
      "\n",
      "[epoch 62] PSNR_test: 23.2192\n",
      "[epoch 63][50/250] loss: 0.0000481941 PSNR_train: 27.6544\n",
      "[epoch 63][100/250] loss: 0.0000483290 PSNR_train: 27.3347\n",
      "[epoch 63][150/250] loss: 0.0000571474 PSNR_train: 26.5685\n",
      "[epoch 63][200/250] loss: 0.0000548601 PSNR_train: 27.0959\n",
      "[epoch 63][250/250] loss: 0.0000625426 PSNR_train: 26.8895\n",
      "\n",
      "[epoch 63] PSNR_test: 23.3634\n",
      "[epoch 64][50/250] loss: 0.0000467395 PSNR_train: 27.8397\n",
      "[epoch 64][100/250] loss: 0.0000530945 PSNR_train: 27.1115\n",
      "[epoch 64][150/250] loss: 0.0000549994 PSNR_train: 27.0846\n",
      "[epoch 64][200/250] loss: 0.0000586588 PSNR_train: 26.5510\n",
      "[epoch 64][250/250] loss: 0.0000563458 PSNR_train: 27.3323\n",
      "\n",
      "[epoch 64] PSNR_test: 23.2665\n",
      "[epoch 65][50/250] loss: 0.0000525276 PSNR_train: 27.0053\n",
      "[epoch 65][100/250] loss: 0.0000447726 PSNR_train: 27.7453\n",
      "[epoch 65][150/250] loss: 0.0000544739 PSNR_train: 27.1941\n",
      "[epoch 65][200/250] loss: 0.0000480476 PSNR_train: 27.4761\n",
      "[epoch 65][250/250] loss: 0.0000464832 PSNR_train: 28.0013\n",
      "\n",
      "[epoch 65] PSNR_test: 23.3335\n",
      "[epoch 66][50/250] loss: 0.0000522205 PSNR_train: 27.1693\n",
      "[epoch 66][100/250] loss: 0.0000462379 PSNR_train: 27.6700\n",
      "[epoch 66][150/250] loss: 0.0000489078 PSNR_train: 27.6482\n",
      "[epoch 66][200/250] loss: 0.0000475080 PSNR_train: 27.4776\n",
      "[epoch 66][250/250] loss: 0.0000392915 PSNR_train: 28.3296\n",
      "\n",
      "[epoch 66] PSNR_test: 23.2847\n",
      "[epoch 67][50/250] loss: 0.0000430625 PSNR_train: 27.9836\n",
      "[epoch 67][100/250] loss: 0.0000522513 PSNR_train: 27.2151\n",
      "[epoch 67][150/250] loss: 0.0000622259 PSNR_train: 27.0120\n",
      "[epoch 67][200/250] loss: 0.0000494972 PSNR_train: 27.5574\n",
      "[epoch 67][250/250] loss: 0.0000493740 PSNR_train: 27.4482\n",
      "\n",
      "[epoch 67] PSNR_test: 23.3238\n",
      "[epoch 68][50/250] loss: 0.0000463208 PSNR_train: 27.7493\n",
      "[epoch 68][100/250] loss: 0.0000440656 PSNR_train: 27.8821\n",
      "[epoch 68][150/250] loss: 0.0000529858 PSNR_train: 27.7640\n",
      "[epoch 68][200/250] loss: 0.0000475051 PSNR_train: 27.6603\n",
      "[epoch 68][250/250] loss: 0.0000597943 PSNR_train: 27.0097\n",
      "\n",
      "[epoch 68] PSNR_test: 23.3069\n",
      "[epoch 69][50/250] loss: 0.0000504700 PSNR_train: 27.3299\n",
      "[epoch 69][100/250] loss: 0.0000572171 PSNR_train: 27.1127\n",
      "[epoch 69][150/250] loss: 0.0000463611 PSNR_train: 27.7485\n",
      "[epoch 69][200/250] loss: 0.0000431551 PSNR_train: 28.1634\n",
      "[epoch 69][250/250] loss: 0.0000482532 PSNR_train: 27.4381\n",
      "\n",
      "[epoch 69] PSNR_test: 23.3946\n",
      "[epoch 70][50/250] loss: 0.0000424468 PSNR_train: 27.8524\n",
      "[epoch 70][100/250] loss: 0.0000373845 PSNR_train: 28.5437\n",
      "[epoch 70][150/250] loss: 0.0000572326 PSNR_train: 26.9173\n",
      "[epoch 70][200/250] loss: 0.0000473160 PSNR_train: 27.7069\n",
      "[epoch 70][250/250] loss: 0.0000532810 PSNR_train: 27.2117\n",
      "\n",
      "[epoch 70] PSNR_test: 23.3437\n",
      "[epoch 71][50/250] loss: 0.0000424091 PSNR_train: 28.1580\n",
      "[epoch 71][100/250] loss: 0.0000398184 PSNR_train: 28.3684\n",
      "[epoch 71][150/250] loss: 0.0000600025 PSNR_train: 26.8081\n",
      "[epoch 71][200/250] loss: 0.0000495203 PSNR_train: 27.5617\n",
      "[epoch 71][250/250] loss: 0.0000487134 PSNR_train: 27.3974\n",
      "\n",
      "[epoch 71] PSNR_test: 23.3301\n",
      "[epoch 72][50/250] loss: 0.0000425401 PSNR_train: 27.8727\n",
      "[epoch 72][100/250] loss: 0.0000419427 PSNR_train: 28.1015\n",
      "[epoch 72][150/250] loss: 0.0000513399 PSNR_train: 27.2253\n",
      "[epoch 72][200/250] loss: 0.0000476923 PSNR_train: 27.5093\n",
      "[epoch 72][250/250] loss: 0.0000486806 PSNR_train: 27.3554\n",
      "\n",
      "[epoch 72] PSNR_test: 23.3194\n",
      "[epoch 73][50/250] loss: 0.0000420001 PSNR_train: 28.3299\n",
      "[epoch 73][100/250] loss: 0.0000472413 PSNR_train: 27.7093\n",
      "[epoch 73][150/250] loss: 0.0000396883 PSNR_train: 28.3277\n",
      "[epoch 73][200/250] loss: 0.0000462291 PSNR_train: 27.6294\n",
      "[epoch 73][250/250] loss: 0.0000488575 PSNR_train: 27.6989\n",
      "\n",
      "[epoch 73] PSNR_test: 23.3899\n",
      "[epoch 74][50/250] loss: 0.0000482084 PSNR_train: 27.4632\n",
      "[epoch 74][100/250] loss: 0.0000476348 PSNR_train: 27.7031\n",
      "[epoch 74][150/250] loss: 0.0000467958 PSNR_train: 27.8182\n",
      "[epoch 74][200/250] loss: 0.0000731068 PSNR_train: 26.3588\n",
      "[epoch 74][250/250] loss: 0.0000543921 PSNR_train: 27.2113\n",
      "\n",
      "[epoch 74] PSNR_test: 23.3708\n",
      "[epoch 75][50/250] loss: 0.0000411508 PSNR_train: 28.1535\n",
      "[epoch 75][100/250] loss: 0.0000456353 PSNR_train: 27.7215\n",
      "[epoch 75][150/250] loss: 0.0000421120 PSNR_train: 28.0271\n",
      "[epoch 75][200/250] loss: 0.0000431804 PSNR_train: 27.8458\n",
      "[epoch 75][250/250] loss: 0.0000496222 PSNR_train: 27.5947\n",
      "\n",
      "[epoch 75] PSNR_test: 23.3826\n",
      "[epoch 76][50/250] loss: 0.0000351873 PSNR_train: 28.8152\n",
      "[epoch 76][100/250] loss: 0.0000561144 PSNR_train: 27.1884\n",
      "[epoch 76][150/250] loss: 0.0000431734 PSNR_train: 28.0305\n",
      "[epoch 76][200/250] loss: 0.0000440473 PSNR_train: 28.1850\n",
      "[epoch 76][250/250] loss: 0.0000440064 PSNR_train: 27.8406\n",
      "\n",
      "[epoch 76] PSNR_test: 23.3507\n",
      "[epoch 77][50/250] loss: 0.0000414403 PSNR_train: 28.1699\n",
      "[epoch 77][100/250] loss: 0.0000482177 PSNR_train: 27.6257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 77][150/250] loss: 0.0000449895 PSNR_train: 28.3547\n",
      "[epoch 77][200/250] loss: 0.0000552534 PSNR_train: 27.1259\n",
      "[epoch 77][250/250] loss: 0.0000512094 PSNR_train: 27.2401\n",
      "\n",
      "[epoch 77] PSNR_test: 23.4121\n",
      "[epoch 78][50/250] loss: 0.0000429601 PSNR_train: 28.0166\n",
      "[epoch 78][100/250] loss: 0.0000381922 PSNR_train: 28.3857\n",
      "[epoch 78][150/250] loss: 0.0000430716 PSNR_train: 27.8940\n",
      "[epoch 78][200/250] loss: 0.0000466150 PSNR_train: 27.6458\n",
      "[epoch 78][250/250] loss: 0.0000424135 PSNR_train: 27.9657\n",
      "\n",
      "[epoch 78] PSNR_test: 23.3518\n",
      "[epoch 79][50/250] loss: 0.0000395999 PSNR_train: 28.2433\n",
      "[epoch 79][100/250] loss: 0.0000430493 PSNR_train: 27.8905\n",
      "[epoch 79][150/250] loss: 0.0000474185 PSNR_train: 27.6311\n",
      "[epoch 79][200/250] loss: 0.0000535199 PSNR_train: 27.2877\n",
      "[epoch 79][250/250] loss: 0.0000481429 PSNR_train: 27.6734\n",
      "\n",
      "[epoch 79] PSNR_test: 23.3563\n",
      "[epoch 80][50/250] loss: 0.0000417392 PSNR_train: 28.0560\n",
      "[epoch 80][100/250] loss: 0.0000427656 PSNR_train: 27.9865\n",
      "[epoch 80][150/250] loss: 0.0000394600 PSNR_train: 28.1723\n",
      "[epoch 80][200/250] loss: 0.0000452576 PSNR_train: 27.8078\n",
      "[epoch 80][250/250] loss: 0.0000503276 PSNR_train: 27.1866\n",
      "\n",
      "[epoch 80] PSNR_test: 23.3809\n",
      "[epoch 81][50/250] loss: 0.0000519537 PSNR_train: 27.4819\n",
      "[epoch 81][100/250] loss: 0.0000388187 PSNR_train: 28.2398\n",
      "[epoch 81][150/250] loss: 0.0000436420 PSNR_train: 27.8293\n",
      "[epoch 81][200/250] loss: 0.0000403341 PSNR_train: 28.0179\n",
      "[epoch 81][250/250] loss: 0.0000470436 PSNR_train: 27.7170\n",
      "\n",
      "[epoch 81] PSNR_test: 23.3695\n",
      "[epoch 82][50/250] loss: 0.0000378385 PSNR_train: 28.4482\n",
      "[epoch 82][100/250] loss: 0.0000336241 PSNR_train: 28.9943\n",
      "[epoch 82][150/250] loss: 0.0000417953 PSNR_train: 28.2235\n",
      "[epoch 82][200/250] loss: 0.0000428293 PSNR_train: 27.9095\n",
      "[epoch 82][250/250] loss: 0.0000444571 PSNR_train: 27.8797\n",
      "\n",
      "[epoch 82] PSNR_test: 23.3388\n",
      "[epoch 83][50/250] loss: 0.0000427316 PSNR_train: 27.9325\n",
      "[epoch 83][100/250] loss: 0.0000381803 PSNR_train: 28.5634\n",
      "[epoch 83][150/250] loss: 0.0000432980 PSNR_train: 28.0079\n",
      "[epoch 83][200/250] loss: 0.0000506264 PSNR_train: 27.2050\n",
      "[epoch 83][250/250] loss: 0.0000436893 PSNR_train: 27.9432\n",
      "\n",
      "[epoch 83] PSNR_test: 23.3014\n",
      "[epoch 84][50/250] loss: 0.0000397639 PSNR_train: 28.0631\n",
      "[epoch 84][100/250] loss: 0.0000442933 PSNR_train: 27.8664\n",
      "[epoch 84][150/250] loss: 0.0000469101 PSNR_train: 27.6835\n",
      "[epoch 84][200/250] loss: 0.0000408400 PSNR_train: 28.1053\n",
      "[epoch 84][250/250] loss: 0.0000494090 PSNR_train: 27.6721\n",
      "\n",
      "[epoch 84] PSNR_test: 23.2145\n",
      "[epoch 85][50/250] loss: 0.0000400324 PSNR_train: 28.3847\n",
      "[epoch 85][100/250] loss: 0.0000408530 PSNR_train: 28.1000\n",
      "[epoch 85][150/250] loss: 0.0000404252 PSNR_train: 28.2732\n",
      "[epoch 85][200/250] loss: 0.0000495297 PSNR_train: 27.2949\n",
      "[epoch 85][250/250] loss: 0.0000434004 PSNR_train: 28.0808\n",
      "\n",
      "[epoch 85] PSNR_test: 23.3951\n",
      "[epoch 86][50/250] loss: 0.0000357625 PSNR_train: 28.7036\n",
      "[epoch 86][100/250] loss: 0.0000382490 PSNR_train: 28.4081\n",
      "[epoch 86][150/250] loss: 0.0000429759 PSNR_train: 28.3260\n",
      "[epoch 86][200/250] loss: 0.0000431576 PSNR_train: 28.0916\n",
      "[epoch 86][250/250] loss: 0.0000527760 PSNR_train: 27.6128\n",
      "\n",
      "[epoch 86] PSNR_test: 23.2326\n",
      "[epoch 87][50/250] loss: 0.0000497466 PSNR_train: 27.5025\n",
      "[epoch 87][100/250] loss: 0.0000459787 PSNR_train: 28.1732\n",
      "[epoch 87][150/250] loss: 0.0000473241 PSNR_train: 27.5038\n",
      "[epoch 87][200/250] loss: 0.0000456612 PSNR_train: 27.9477\n",
      "[epoch 87][250/250] loss: 0.0000467762 PSNR_train: 27.7353\n",
      "\n",
      "[epoch 87] PSNR_test: 23.1911\n",
      "[epoch 88][50/250] loss: 0.0000355931 PSNR_train: 28.6139\n",
      "[epoch 88][100/250] loss: 0.0000464238 PSNR_train: 27.5630\n",
      "[epoch 88][150/250] loss: 0.0000422828 PSNR_train: 28.1770\n",
      "[epoch 88][200/250] loss: 0.0000389041 PSNR_train: 28.2195\n",
      "[epoch 88][250/250] loss: 0.0000434933 PSNR_train: 28.2598\n",
      "\n",
      "[epoch 88] PSNR_test: 23.3366\n",
      "[epoch 89][50/250] loss: 0.0000471762 PSNR_train: 28.1480\n",
      "[epoch 89][100/250] loss: 0.0000415317 PSNR_train: 28.5542\n",
      "[epoch 89][150/250] loss: 0.0000440462 PSNR_train: 27.7842\n",
      "[epoch 89][200/250] loss: 0.0000409186 PSNR_train: 28.2563\n",
      "[epoch 89][250/250] loss: 0.0000439868 PSNR_train: 27.8011\n",
      "\n",
      "[epoch 89] PSNR_test: 23.2926\n",
      "[epoch 90][50/250] loss: 0.0000454572 PSNR_train: 27.9059\n",
      "[epoch 90][100/250] loss: 0.0000417500 PSNR_train: 28.2264\n",
      "[epoch 90][150/250] loss: 0.0000398784 PSNR_train: 28.2368\n",
      "[epoch 90][200/250] loss: 0.0000439278 PSNR_train: 27.8492\n",
      "[epoch 90][250/250] loss: 0.0000473829 PSNR_train: 27.7335\n",
      "\n",
      "[epoch 90] PSNR_test: 23.3554\n",
      "[epoch 91][50/250] loss: 0.0000396791 PSNR_train: 28.3361\n",
      "[epoch 91][100/250] loss: 0.0000425210 PSNR_train: 28.0843\n",
      "[epoch 91][150/250] loss: 0.0000387327 PSNR_train: 28.5478\n",
      "[epoch 91][200/250] loss: 0.0000381624 PSNR_train: 28.3703\n",
      "[epoch 91][250/250] loss: 0.0000434501 PSNR_train: 28.2005\n",
      "\n",
      "[epoch 91] PSNR_test: 23.3679\n",
      "[epoch 92][50/250] loss: 0.0000401314 PSNR_train: 28.2709\n",
      "[epoch 92][100/250] loss: 0.0000557513 PSNR_train: 27.1163\n",
      "[epoch 92][150/250] loss: 0.0000428739 PSNR_train: 28.0832\n",
      "[epoch 92][200/250] loss: 0.0000449859 PSNR_train: 27.7523\n",
      "[epoch 92][250/250] loss: 0.0000411271 PSNR_train: 28.2420\n",
      "\n",
      "[epoch 92] PSNR_test: 23.3499\n",
      "[epoch 93][50/250] loss: 0.0000416337 PSNR_train: 28.3576\n",
      "[epoch 93][100/250] loss: 0.0000414644 PSNR_train: 28.1670\n",
      "[epoch 93][150/250] loss: 0.0000393518 PSNR_train: 28.3845\n",
      "[epoch 93][200/250] loss: 0.0000451235 PSNR_train: 27.7447\n",
      "[epoch 93][250/250] loss: 0.0000523333 PSNR_train: 27.2501\n",
      "\n",
      "[epoch 93] PSNR_test: 23.3497\n",
      "[epoch 94][50/250] loss: 0.0000403103 PSNR_train: 28.1935\n",
      "[epoch 94][100/250] loss: 0.0000457029 PSNR_train: 27.8012\n",
      "[epoch 94][150/250] loss: 0.0000436397 PSNR_train: 27.8702\n",
      "[epoch 94][200/250] loss: 0.0000511467 PSNR_train: 27.1977\n",
      "[epoch 94][250/250] loss: 0.0000423488 PSNR_train: 28.0592\n",
      "\n",
      "[epoch 94] PSNR_test: 23.2748\n",
      "[epoch 95][50/250] loss: 0.0000528816 PSNR_train: 27.2174\n",
      "[epoch 95][100/250] loss: 0.0000424497 PSNR_train: 27.9756\n",
      "[epoch 95][150/250] loss: 0.0000445977 PSNR_train: 28.0159\n",
      "[epoch 95][200/250] loss: 0.0000369966 PSNR_train: 28.6253\n",
      "[epoch 95][250/250] loss: 0.0000444742 PSNR_train: 28.1000\n",
      "\n",
      "[epoch 95] PSNR_test: 23.3464\n",
      "[epoch 96][50/250] loss: 0.0000369011 PSNR_train: 28.5716\n",
      "[epoch 96][100/250] loss: 0.0000397985 PSNR_train: 28.5932\n",
      "[epoch 96][150/250] loss: 0.0000410872 PSNR_train: 28.0539\n",
      "[epoch 96][200/250] loss: 0.0000375527 PSNR_train: 28.4465\n",
      "[epoch 96][250/250] loss: 0.0000498778 PSNR_train: 27.1785\n",
      "\n",
      "[epoch 96] PSNR_test: 23.3090\n",
      "[epoch 97][50/250] loss: 0.0000336816 PSNR_train: 29.1489\n",
      "[epoch 97][100/250] loss: 0.0000430825 PSNR_train: 27.8392\n",
      "[epoch 97][150/250] loss: 0.0000349589 PSNR_train: 28.9656\n",
      "[epoch 97][200/250] loss: 0.0000468907 PSNR_train: 27.5570\n",
      "[epoch 97][250/250] loss: 0.0000468737 PSNR_train: 27.7354\n",
      "\n",
      "[epoch 97] PSNR_test: 23.2709\n",
      "[epoch 98][50/250] loss: 0.0000422474 PSNR_train: 28.2084\n",
      "[epoch 98][100/250] loss: 0.0000367986 PSNR_train: 28.5361\n",
      "[epoch 98][150/250] loss: 0.0000374080 PSNR_train: 28.5202\n",
      "[epoch 98][200/250] loss: 0.0000368390 PSNR_train: 28.6310\n",
      "[epoch 98][250/250] loss: 0.0000422054 PSNR_train: 28.0572\n",
      "\n",
      "[epoch 98] PSNR_test: 23.3206\n",
      "[epoch 99][50/250] loss: 0.0000373967 PSNR_train: 28.6575\n",
      "[epoch 99][100/250] loss: 0.0000467454 PSNR_train: 27.5727\n",
      "[epoch 99][150/250] loss: 0.0000430638 PSNR_train: 28.0036\n",
      "[epoch 99][200/250] loss: 0.0000393704 PSNR_train: 28.3193\n",
      "[epoch 99][250/250] loss: 0.0000485249 PSNR_train: 27.5013\n",
      "\n",
      "[epoch 99] PSNR_test: 23.3696\n",
      "[epoch 100][50/250] loss: 0.0000366341 PSNR_train: 28.7357\n",
      "[epoch 100][100/250] loss: 0.0000440449 PSNR_train: 28.1495\n",
      "[epoch 100][150/250] loss: 0.0000456694 PSNR_train: 27.8920\n",
      "[epoch 100][200/250] loss: 0.0000401174 PSNR_train: 28.1438\n",
      "[epoch 100][250/250] loss: 0.0000425845 PSNR_train: 28.3083\n",
      "\n",
      "[epoch 100] PSNR_test: 23.3718\n",
      "[epoch 101][50/250] loss: 0.0000451283 PSNR_train: 27.6250\n",
      "[epoch 101][100/250] loss: 0.0000363536 PSNR_train: 28.7682\n",
      "[epoch 101][150/250] loss: 0.0000485895 PSNR_train: 27.4944\n",
      "[epoch 101][200/250] loss: 0.0000395427 PSNR_train: 28.4415\n",
      "[epoch 101][250/250] loss: 0.0000430909 PSNR_train: 28.0244\n",
      "\n",
      "[epoch 101] PSNR_test: 23.3198\n",
      "[epoch 102][50/250] loss: 0.0000369045 PSNR_train: 28.7455\n",
      "[epoch 102][100/250] loss: 0.0000388398 PSNR_train: 28.2665\n",
      "[epoch 102][150/250] loss: 0.0000394478 PSNR_train: 28.5880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 102][200/250] loss: 0.0000446628 PSNR_train: 27.6303\n",
      "[epoch 102][250/250] loss: 0.0000348736 PSNR_train: 28.7808\n",
      "\n",
      "[epoch 102] PSNR_test: 23.1429\n",
      "[epoch 103][50/250] loss: 0.0000365980 PSNR_train: 28.5665\n",
      "[epoch 103][100/250] loss: 0.0000474072 PSNR_train: 27.4863\n",
      "[epoch 103][150/250] loss: 0.0000474943 PSNR_train: 27.3597\n",
      "[epoch 103][200/250] loss: 0.0000421167 PSNR_train: 27.8642\n",
      "[epoch 103][250/250] loss: 0.0000408450 PSNR_train: 28.2924\n",
      "\n",
      "[epoch 103] PSNR_test: 23.3076\n",
      "[epoch 104][50/250] loss: 0.0000405681 PSNR_train: 28.2313\n",
      "[epoch 104][100/250] loss: 0.0000347323 PSNR_train: 28.8201\n",
      "[epoch 104][150/250] loss: 0.0000396402 PSNR_train: 28.4090\n",
      "[epoch 104][200/250] loss: 0.0000480785 PSNR_train: 27.8281\n",
      "[epoch 104][250/250] loss: 0.0000405233 PSNR_train: 28.5329\n",
      "\n",
      "[epoch 104] PSNR_test: 23.2934\n",
      "[epoch 105][50/250] loss: 0.0000349813 PSNR_train: 28.9410\n",
      "[epoch 105][100/250] loss: 0.0000390294 PSNR_train: 28.3979\n",
      "[epoch 105][150/250] loss: 0.0000373515 PSNR_train: 28.5708\n",
      "[epoch 105][200/250] loss: 0.0000363566 PSNR_train: 28.8509\n",
      "[epoch 105][250/250] loss: 0.0000359486 PSNR_train: 28.7240\n",
      "\n",
      "[epoch 105] PSNR_test: 23.3246\n",
      "[epoch 106][50/250] loss: 0.0000427158 PSNR_train: 27.9970\n",
      "[epoch 106][100/250] loss: 0.0000325823 PSNR_train: 29.0979\n",
      "[epoch 106][150/250] loss: 0.0000370207 PSNR_train: 28.4965\n",
      "[epoch 106][200/250] loss: 0.0000461324 PSNR_train: 27.8428\n",
      "[epoch 106][250/250] loss: 0.0000366918 PSNR_train: 28.6378\n",
      "\n",
      "[epoch 106] PSNR_test: 23.2613\n",
      "[epoch 107][50/250] loss: 0.0000376684 PSNR_train: 28.3735\n",
      "[epoch 107][100/250] loss: 0.0000412722 PSNR_train: 27.9312\n",
      "[epoch 107][150/250] loss: 0.0000410308 PSNR_train: 28.2636\n",
      "[epoch 107][200/250] loss: 0.0000391973 PSNR_train: 28.6382\n",
      "[epoch 107][250/250] loss: 0.0000420791 PSNR_train: 28.1642\n",
      "\n",
      "[epoch 107] PSNR_test: 23.3567\n",
      "[epoch 108][50/250] loss: 0.0000387800 PSNR_train: 28.2084\n",
      "[epoch 108][100/250] loss: 0.0000420477 PSNR_train: 28.0213\n",
      "[epoch 108][150/250] loss: 0.0000377799 PSNR_train: 28.6594\n",
      "[epoch 108][200/250] loss: 0.0000493769 PSNR_train: 27.6257\n",
      "[epoch 108][250/250] loss: 0.0000385384 PSNR_train: 28.5463\n",
      "\n",
      "[epoch 108] PSNR_test: 23.2751\n",
      "[epoch 109][50/250] loss: 0.0000408050 PSNR_train: 28.2158\n",
      "[epoch 109][100/250] loss: 0.0000358304 PSNR_train: 28.6344\n",
      "[epoch 109][150/250] loss: 0.0000364925 PSNR_train: 28.7637\n",
      "[epoch 109][200/250] loss: 0.0000367182 PSNR_train: 28.6606\n",
      "[epoch 109][250/250] loss: 0.0000367724 PSNR_train: 28.4383\n",
      "\n",
      "[epoch 109] PSNR_test: 23.3440\n",
      "[epoch 110][50/250] loss: 0.0000353294 PSNR_train: 28.8256\n",
      "[epoch 110][100/250] loss: 0.0000398842 PSNR_train: 28.3201\n",
      "[epoch 110][150/250] loss: 0.0000384025 PSNR_train: 28.4704\n",
      "[epoch 110][200/250] loss: 0.0000433668 PSNR_train: 28.0384\n",
      "[epoch 110][250/250] loss: 0.0000363856 PSNR_train: 28.5980\n",
      "\n",
      "[epoch 110] PSNR_test: 23.2469\n",
      "[epoch 111][50/250] loss: 0.0000304022 PSNR_train: 29.4615\n",
      "[epoch 111][100/250] loss: 0.0000388768 PSNR_train: 28.4726\n",
      "[epoch 111][150/250] loss: 0.0000357658 PSNR_train: 28.9722\n",
      "[epoch 111][200/250] loss: 0.0000494321 PSNR_train: 27.5271\n",
      "[epoch 111][250/250] loss: 0.0000380795 PSNR_train: 28.3788\n",
      "\n",
      "[epoch 111] PSNR_test: 23.3711\n",
      "[epoch 112][50/250] loss: 0.0000386515 PSNR_train: 28.3809\n",
      "[epoch 112][100/250] loss: 0.0000392513 PSNR_train: 28.3874\n",
      "[epoch 112][150/250] loss: 0.0000374206 PSNR_train: 28.5759\n",
      "[epoch 112][200/250] loss: 0.0000417050 PSNR_train: 28.0150\n",
      "[epoch 112][250/250] loss: 0.0000376094 PSNR_train: 28.5049\n",
      "\n",
      "[epoch 112] PSNR_test: 23.3698\n",
      "[epoch 113][50/250] loss: 0.0000382436 PSNR_train: 28.5864\n",
      "[epoch 113][100/250] loss: 0.0000380530 PSNR_train: 28.4349\n",
      "[epoch 113][150/250] loss: 0.0000354067 PSNR_train: 28.9170\n",
      "[epoch 113][200/250] loss: 0.0000413237 PSNR_train: 28.1252\n",
      "[epoch 113][250/250] loss: 0.0000400711 PSNR_train: 28.2700\n",
      "\n",
      "[epoch 113] PSNR_test: 23.3196\n",
      "[epoch 114][50/250] loss: 0.0000446930 PSNR_train: 27.7935\n",
      "[epoch 114][100/250] loss: 0.0000370451 PSNR_train: 28.4439\n",
      "[epoch 114][150/250] loss: 0.0000381060 PSNR_train: 28.3160\n",
      "[epoch 114][200/250] loss: 0.0000371189 PSNR_train: 28.4884\n",
      "[epoch 114][250/250] loss: 0.0000366510 PSNR_train: 28.6362\n",
      "\n",
      "[epoch 114] PSNR_test: 23.2142\n",
      "[epoch 115][50/250] loss: 0.0000399075 PSNR_train: 28.4440\n",
      "[epoch 115][100/250] loss: 0.0000414607 PSNR_train: 28.2187\n",
      "[epoch 115][150/250] loss: 0.0000376984 PSNR_train: 28.5598\n",
      "[epoch 115][200/250] loss: 0.0000357955 PSNR_train: 28.6851\n",
      "[epoch 115][250/250] loss: 0.0000400167 PSNR_train: 28.4160\n",
      "\n",
      "[epoch 115] PSNR_test: 23.3140\n",
      "[epoch 116][50/250] loss: 0.0000353285 PSNR_train: 28.7560\n",
      "[epoch 116][100/250] loss: 0.0000329638 PSNR_train: 29.0718\n",
      "[epoch 116][150/250] loss: 0.0000409260 PSNR_train: 28.0298\n",
      "[epoch 116][200/250] loss: 0.0000386628 PSNR_train: 28.3257\n",
      "[epoch 116][250/250] loss: 0.0000382590 PSNR_train: 28.4768\n",
      "\n",
      "[epoch 116] PSNR_test: 23.2611\n",
      "[epoch 117][50/250] loss: 0.0000342841 PSNR_train: 29.0283\n",
      "[epoch 117][100/250] loss: 0.0000332945 PSNR_train: 29.1598\n",
      "[epoch 117][150/250] loss: 0.0000333647 PSNR_train: 28.9495\n",
      "[epoch 117][200/250] loss: 0.0000356118 PSNR_train: 28.6063\n",
      "[epoch 117][250/250] loss: 0.0000424169 PSNR_train: 28.1530\n",
      "\n",
      "[epoch 117] PSNR_test: 23.3008\n",
      "[epoch 118][50/250] loss: 0.0000341801 PSNR_train: 28.8171\n",
      "[epoch 118][100/250] loss: 0.0000369248 PSNR_train: 28.8241\n",
      "[epoch 118][150/250] loss: 0.0000393612 PSNR_train: 28.3360\n",
      "[epoch 118][200/250] loss: 0.0000377816 PSNR_train: 28.4403\n",
      "[epoch 118][250/250] loss: 0.0000347171 PSNR_train: 28.8161\n",
      "\n",
      "[epoch 118] PSNR_test: 23.1871\n",
      "[epoch 119][50/250] loss: 0.0000387699 PSNR_train: 28.2956\n",
      "[epoch 119][100/250] loss: 0.0000340057 PSNR_train: 28.9135\n",
      "[epoch 119][150/250] loss: 0.0000363514 PSNR_train: 28.7144\n",
      "[epoch 119][200/250] loss: 0.0000320575 PSNR_train: 29.1743\n",
      "[epoch 119][250/250] loss: 0.0000437626 PSNR_train: 27.8946\n",
      "\n",
      "[epoch 119] PSNR_test: 23.3136\n",
      "[epoch 120][50/250] loss: 0.0000310124 PSNR_train: 29.3472\n",
      "[epoch 120][100/250] loss: 0.0000380781 PSNR_train: 28.5512\n",
      "[epoch 120][150/250] loss: 0.0000356633 PSNR_train: 28.6474\n",
      "[epoch 120][200/250] loss: 0.0000384022 PSNR_train: 28.6489\n",
      "[epoch 120][250/250] loss: 0.0000379377 PSNR_train: 28.3928\n",
      "\n",
      "[epoch 120] PSNR_test: 23.2855\n",
      "[epoch 121][50/250] loss: 0.0000292119 PSNR_train: 29.5542\n",
      "[epoch 121][100/250] loss: 0.0000366982 PSNR_train: 28.6913\n",
      "[epoch 121][150/250] loss: 0.0000340568 PSNR_train: 28.7821\n",
      "[epoch 121][200/250] loss: 0.0000386841 PSNR_train: 28.4191\n",
      "[epoch 121][250/250] loss: 0.0000346293 PSNR_train: 28.8912\n",
      "\n",
      "[epoch 121] PSNR_test: 23.3320\n",
      "[epoch 122][50/250] loss: 0.0000333586 PSNR_train: 29.0288\n",
      "[epoch 122][100/250] loss: 0.0000315901 PSNR_train: 29.0981\n",
      "[epoch 122][150/250] loss: 0.0000323235 PSNR_train: 29.2304\n",
      "[epoch 122][200/250] loss: 0.0000384310 PSNR_train: 28.3601\n",
      "[epoch 122][250/250] loss: 0.0000385185 PSNR_train: 28.2141\n",
      "\n",
      "[epoch 122] PSNR_test: 23.3702\n",
      "[epoch 123][50/250] loss: 0.0000327859 PSNR_train: 29.2115\n",
      "[epoch 123][100/250] loss: 0.0000379070 PSNR_train: 28.5689\n",
      "[epoch 123][150/250] loss: 0.0000379311 PSNR_train: 28.3668\n",
      "[epoch 123][200/250] loss: 0.0000461543 PSNR_train: 27.5156\n",
      "[epoch 123][250/250] loss: 0.0000359166 PSNR_train: 28.6353\n",
      "\n",
      "[epoch 123] PSNR_test: 23.3182\n",
      "[epoch 124][50/250] loss: 0.0000343758 PSNR_train: 28.7773\n",
      "[epoch 124][100/250] loss: 0.0000327500 PSNR_train: 29.1841\n",
      "[epoch 124][150/250] loss: 0.0000379703 PSNR_train: 28.5887\n",
      "[epoch 124][200/250] loss: 0.0000356052 PSNR_train: 28.6607\n",
      "[epoch 124][250/250] loss: 0.0000392138 PSNR_train: 28.1879\n",
      "\n",
      "[epoch 124] PSNR_test: 23.3155\n",
      "[epoch 125][50/250] loss: 0.0000359407 PSNR_train: 28.6540\n",
      "[epoch 125][100/250] loss: 0.0000378446 PSNR_train: 28.7506\n",
      "[epoch 125][150/250] loss: 0.0000329886 PSNR_train: 29.0514\n",
      "[epoch 125][200/250] loss: 0.0000400833 PSNR_train: 28.2490\n",
      "[epoch 125][250/250] loss: 0.0000376196 PSNR_train: 28.4610\n",
      "\n",
      "[epoch 125] PSNR_test: 23.3023\n",
      "[epoch 126][50/250] loss: 0.0000312467 PSNR_train: 29.2770\n",
      "[epoch 126][100/250] loss: 0.0000342093 PSNR_train: 28.7792\n",
      "[epoch 126][150/250] loss: 0.0000415511 PSNR_train: 28.0156\n",
      "[epoch 126][200/250] loss: 0.0000344067 PSNR_train: 28.7438\n",
      "[epoch 126][250/250] loss: 0.0000363328 PSNR_train: 28.5378\n",
      "\n",
      "[epoch 126] PSNR_test: 23.3096\n",
      "[epoch 127][50/250] loss: 0.0000320583 PSNR_train: 29.1287\n",
      "[epoch 127][100/250] loss: 0.0000312254 PSNR_train: 29.2937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 127][150/250] loss: 0.0000306368 PSNR_train: 29.4050\n",
      "[epoch 127][200/250] loss: 0.0000373729 PSNR_train: 28.6920\n",
      "[epoch 127][250/250] loss: 0.0000358569 PSNR_train: 28.5966\n",
      "\n",
      "[epoch 127] PSNR_test: 23.3199\n",
      "[epoch 128][50/250] loss: 0.0000339138 PSNR_train: 28.8134\n",
      "[epoch 128][100/250] loss: 0.0000375815 PSNR_train: 28.5802\n",
      "[epoch 128][150/250] loss: 0.0000343971 PSNR_train: 28.8655\n",
      "[epoch 128][200/250] loss: 0.0000367390 PSNR_train: 28.6948\n",
      "[epoch 128][250/250] loss: 0.0000306235 PSNR_train: 29.4411\n",
      "\n",
      "[epoch 128] PSNR_test: 23.3366\n",
      "[epoch 129][50/250] loss: 0.0000358174 PSNR_train: 28.5813\n",
      "[epoch 129][100/250] loss: 0.0000330948 PSNR_train: 28.8644\n",
      "[epoch 129][150/250] loss: 0.0000388282 PSNR_train: 28.3368\n",
      "[epoch 129][200/250] loss: 0.0000354944 PSNR_train: 28.8916\n",
      "[epoch 129][250/250] loss: 0.0000396241 PSNR_train: 28.3273\n",
      "\n",
      "[epoch 129] PSNR_test: 23.3323\n",
      "[epoch 130][50/250] loss: 0.0000336629 PSNR_train: 28.8319\n",
      "[epoch 130][100/250] loss: 0.0000357033 PSNR_train: 28.6852\n",
      "[epoch 130][150/250] loss: 0.0000306397 PSNR_train: 29.2730\n",
      "[epoch 130][200/250] loss: 0.0000375046 PSNR_train: 28.4268\n",
      "[epoch 130][250/250] loss: 0.0000325438 PSNR_train: 29.0640\n",
      "\n",
      "[epoch 130] PSNR_test: 23.3085\n",
      "[epoch 131][50/250] loss: 0.0000306736 PSNR_train: 29.3316\n",
      "[epoch 131][100/250] loss: 0.0000386552 PSNR_train: 28.4705\n",
      "[epoch 131][150/250] loss: 0.0000311501 PSNR_train: 29.3626\n",
      "[epoch 131][200/250] loss: 0.0000392067 PSNR_train: 28.2961\n",
      "[epoch 131][250/250] loss: 0.0000363730 PSNR_train: 28.5553\n",
      "\n",
      "[epoch 131] PSNR_test: 23.3178\n",
      "[epoch 132][50/250] loss: 0.0000321381 PSNR_train: 29.1962\n",
      "[epoch 132][100/250] loss: 0.0000369252 PSNR_train: 28.6747\n",
      "[epoch 132][150/250] loss: 0.0000330064 PSNR_train: 28.9787\n",
      "[epoch 132][200/250] loss: 0.0000402102 PSNR_train: 28.2141\n",
      "[epoch 132][250/250] loss: 0.0000387018 PSNR_train: 28.3248\n",
      "\n",
      "[epoch 132] PSNR_test: 23.3364\n",
      "[epoch 133][50/250] loss: 0.0000312644 PSNR_train: 29.3276\n",
      "[epoch 133][100/250] loss: 0.0000328576 PSNR_train: 29.0498\n",
      "[epoch 133][150/250] loss: 0.0000342775 PSNR_train: 28.9876\n",
      "[epoch 133][200/250] loss: 0.0000357426 PSNR_train: 28.6452\n",
      "[epoch 133][250/250] loss: 0.0000332433 PSNR_train: 29.2402\n",
      "\n",
      "[epoch 133] PSNR_test: 23.3403\n",
      "[epoch 134][50/250] loss: 0.0000370818 PSNR_train: 28.5853\n",
      "[epoch 134][100/250] loss: 0.0000333179 PSNR_train: 29.0530\n",
      "[epoch 134][150/250] loss: 0.0000362105 PSNR_train: 28.5421\n",
      "[epoch 134][200/250] loss: 0.0000409425 PSNR_train: 28.0862\n",
      "[epoch 134][250/250] loss: 0.0000305101 PSNR_train: 29.4123\n",
      "\n",
      "[epoch 134] PSNR_test: 23.3621\n",
      "[epoch 135][50/250] loss: 0.0000328158 PSNR_train: 29.1587\n",
      "[epoch 135][100/250] loss: 0.0000311607 PSNR_train: 29.3551\n",
      "[epoch 135][150/250] loss: 0.0000281109 PSNR_train: 29.6088\n",
      "[epoch 135][200/250] loss: 0.0000397751 PSNR_train: 28.2774\n",
      "[epoch 135][250/250] loss: 0.0000375458 PSNR_train: 28.3836\n",
      "\n",
      "[epoch 135] PSNR_test: 23.3022\n",
      "[epoch 136][50/250] loss: 0.0000319849 PSNR_train: 29.1501\n",
      "[epoch 136][100/250] loss: 0.0000311263 PSNR_train: 29.2887\n",
      "[epoch 136][150/250] loss: 0.0000328392 PSNR_train: 29.0279\n",
      "[epoch 136][200/250] loss: 0.0000379338 PSNR_train: 28.6028\n",
      "[epoch 136][250/250] loss: 0.0000378389 PSNR_train: 28.5359\n",
      "\n",
      "[epoch 136] PSNR_test: 23.3806\n",
      "[epoch 137][50/250] loss: 0.0000380862 PSNR_train: 28.4723\n",
      "[epoch 137][100/250] loss: 0.0000361547 PSNR_train: 28.7247\n",
      "[epoch 137][150/250] loss: 0.0000368538 PSNR_train: 28.5292\n",
      "[epoch 137][200/250] loss: 0.0000340048 PSNR_train: 28.7526\n",
      "[epoch 137][250/250] loss: 0.0000350532 PSNR_train: 28.8383\n",
      "\n",
      "[epoch 137] PSNR_test: 23.2826\n",
      "[epoch 138][50/250] loss: 0.0000352518 PSNR_train: 28.6490\n",
      "[epoch 138][100/250] loss: 0.0000360594 PSNR_train: 28.6320\n",
      "[epoch 138][150/250] loss: 0.0000317245 PSNR_train: 29.2558\n",
      "[epoch 138][200/250] loss: 0.0000313883 PSNR_train: 29.2027\n",
      "[epoch 138][250/250] loss: 0.0000277462 PSNR_train: 29.7721\n",
      "\n",
      "[epoch 138] PSNR_test: 23.3248\n",
      "[epoch 139][50/250] loss: 0.0000309471 PSNR_train: 29.3535\n",
      "[epoch 139][100/250] loss: 0.0000391853 PSNR_train: 28.4432\n",
      "[epoch 139][150/250] loss: 0.0000344019 PSNR_train: 28.6996\n",
      "[epoch 139][200/250] loss: 0.0000347582 PSNR_train: 28.7977\n",
      "[epoch 139][250/250] loss: 0.0000348452 PSNR_train: 28.8429\n",
      "\n",
      "[epoch 139] PSNR_test: 23.2801\n",
      "[epoch 140][50/250] loss: 0.0000336627 PSNR_train: 29.1251\n",
      "[epoch 140][100/250] loss: 0.0000385763 PSNR_train: 28.3893\n",
      "[epoch 140][150/250] loss: 0.0000343641 PSNR_train: 28.9250\n",
      "[epoch 140][200/250] loss: 0.0000349173 PSNR_train: 28.7847\n",
      "[epoch 140][250/250] loss: 0.0000334283 PSNR_train: 29.0840\n",
      "\n",
      "[epoch 140] PSNR_test: 23.3433\n",
      "[epoch 141][50/250] loss: 0.0000325546 PSNR_train: 29.0480\n",
      "[epoch 141][100/250] loss: 0.0000321561 PSNR_train: 29.1172\n",
      "[epoch 141][150/250] loss: 0.0000399196 PSNR_train: 28.1038\n",
      "[epoch 141][200/250] loss: 0.0000303792 PSNR_train: 29.3100\n",
      "[epoch 141][250/250] loss: 0.0000303807 PSNR_train: 29.3827\n",
      "\n",
      "[epoch 141] PSNR_test: 23.2594\n",
      "[epoch 142][50/250] loss: 0.0000322339 PSNR_train: 29.1419\n",
      "[epoch 142][100/250] loss: 0.0000303826 PSNR_train: 29.3886\n",
      "[epoch 142][150/250] loss: 0.0000350344 PSNR_train: 28.8389\n",
      "[epoch 142][200/250] loss: 0.0000326170 PSNR_train: 29.1993\n",
      "[epoch 142][250/250] loss: 0.0000330614 PSNR_train: 29.0017\n",
      "\n",
      "[epoch 142] PSNR_test: 23.3313\n",
      "[epoch 143][50/250] loss: 0.0000355933 PSNR_train: 28.7180\n",
      "[epoch 143][100/250] loss: 0.0000280522 PSNR_train: 29.7395\n",
      "[epoch 143][150/250] loss: 0.0000350509 PSNR_train: 28.7994\n",
      "[epoch 143][200/250] loss: 0.0000388096 PSNR_train: 28.2834\n",
      "[epoch 143][250/250] loss: 0.0000319503 PSNR_train: 29.1080\n",
      "\n",
      "[epoch 143] PSNR_test: 23.2917\n",
      "[epoch 144][50/250] loss: 0.0000302126 PSNR_train: 29.3973\n",
      "[epoch 144][100/250] loss: 0.0000295658 PSNR_train: 29.3894\n",
      "[epoch 144][150/250] loss: 0.0000320619 PSNR_train: 29.0713\n",
      "[epoch 144][200/250] loss: 0.0000307954 PSNR_train: 29.4495\n",
      "[epoch 144][250/250] loss: 0.0000312569 PSNR_train: 29.3176\n",
      "\n",
      "[epoch 144] PSNR_test: 23.3377\n",
      "[epoch 145][50/250] loss: 0.0000373430 PSNR_train: 28.5345\n",
      "[epoch 145][100/250] loss: 0.0000277031 PSNR_train: 29.8075\n",
      "[epoch 145][150/250] loss: 0.0000302297 PSNR_train: 29.4044\n",
      "[epoch 145][200/250] loss: 0.0000303226 PSNR_train: 29.3327\n",
      "[epoch 145][250/250] loss: 0.0000406806 PSNR_train: 28.1146\n",
      "\n",
      "[epoch 145] PSNR_test: 23.2835\n",
      "[epoch 146][50/250] loss: 0.0000352094 PSNR_train: 28.8808\n",
      "[epoch 146][100/250] loss: 0.0000303521 PSNR_train: 29.2977\n",
      "[epoch 146][150/250] loss: 0.0000351333 PSNR_train: 28.7522\n",
      "[epoch 146][200/250] loss: 0.0000315614 PSNR_train: 29.1761\n",
      "[epoch 146][250/250] loss: 0.0000330419 PSNR_train: 29.0465\n",
      "\n",
      "[epoch 146] PSNR_test: 23.3073\n",
      "[epoch 147][50/250] loss: 0.0000290935 PSNR_train: 29.5151\n",
      "[epoch 147][100/250] loss: 0.0000308977 PSNR_train: 29.4635\n",
      "[epoch 147][150/250] loss: 0.0000380478 PSNR_train: 28.5747\n",
      "[epoch 147][200/250] loss: 0.0000398384 PSNR_train: 28.1376\n",
      "[epoch 147][250/250] loss: 0.0000336384 PSNR_train: 28.8172\n",
      "\n",
      "[epoch 147] PSNR_test: 23.2998\n",
      "[epoch 148][50/250] loss: 0.0000306410 PSNR_train: 29.3167\n",
      "[epoch 148][100/250] loss: 0.0000321353 PSNR_train: 29.1357\n",
      "[epoch 148][150/250] loss: 0.0000312172 PSNR_train: 29.2168\n",
      "[epoch 148][200/250] loss: 0.0000360918 PSNR_train: 28.6506\n",
      "[epoch 148][250/250] loss: 0.0000352211 PSNR_train: 28.8107\n",
      "\n",
      "[epoch 148] PSNR_test: 23.2020\n",
      "[epoch 149][50/250] loss: 0.0000282354 PSNR_train: 29.6830\n",
      "[epoch 149][100/250] loss: 0.0000314964 PSNR_train: 29.1709\n",
      "[epoch 149][150/250] loss: 0.0000284343 PSNR_train: 29.7177\n",
      "[epoch 149][200/250] loss: 0.0000371257 PSNR_train: 28.4375\n",
      "[epoch 149][250/250] loss: 0.0000344122 PSNR_train: 28.8254\n",
      "\n",
      "[epoch 149] PSNR_test: 23.2946\n",
      "[epoch 150][50/250] loss: 0.0000361780 PSNR_train: 28.7231\n",
      "[epoch 150][100/250] loss: 0.0000310744 PSNR_train: 29.5125\n",
      "[epoch 150][150/250] loss: 0.0000351661 PSNR_train: 28.7447\n",
      "[epoch 150][200/250] loss: 0.0000348556 PSNR_train: 28.8065\n",
      "[epoch 150][250/250] loss: 0.0000351646 PSNR_train: 28.6524\n",
      "\n",
      "[epoch 150] PSNR_test: 23.2992\n",
      "[epoch 151][50/250] loss: 0.0000322616 PSNR_train: 29.2451\n",
      "[epoch 151][100/250] loss: 0.0000303401 PSNR_train: 29.4487\n",
      "[epoch 151][150/250] loss: 0.0000315846 PSNR_train: 29.1615\n",
      "[epoch 151][200/250] loss: 0.0000357655 PSNR_train: 28.6427\n",
      "[epoch 151][250/250] loss: 0.0000367845 PSNR_train: 28.6497\n",
      "\n",
      "[epoch 151] PSNR_test: 23.2915\n",
      "[epoch 152][50/250] loss: 0.0000341959 PSNR_train: 28.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 152][100/250] loss: 0.0000319078 PSNR_train: 29.2222\n",
      "[epoch 152][150/250] loss: 0.0000323131 PSNR_train: 29.1979\n",
      "[epoch 152][200/250] loss: 0.0000310583 PSNR_train: 29.2005\n",
      "[epoch 152][250/250] loss: 0.0000296646 PSNR_train: 29.5779\n",
      "\n",
      "[epoch 152] PSNR_test: 23.2568\n",
      "[epoch 153][50/250] loss: 0.0000316561 PSNR_train: 29.2164\n",
      "[epoch 153][100/250] loss: 0.0000288581 PSNR_train: 29.7531\n",
      "[epoch 153][150/250] loss: 0.0000286594 PSNR_train: 29.6330\n",
      "[epoch 153][200/250] loss: 0.0000328653 PSNR_train: 29.0663\n",
      "[epoch 153][250/250] loss: 0.0000372493 PSNR_train: 28.5209\n",
      "\n",
      "[epoch 153] PSNR_test: 23.2107\n",
      "[epoch 154][50/250] loss: 0.0000329216 PSNR_train: 29.1343\n",
      "[epoch 154][100/250] loss: 0.0000299180 PSNR_train: 29.5185\n",
      "[epoch 154][150/250] loss: 0.0000361409 PSNR_train: 28.7647\n",
      "[epoch 154][200/250] loss: 0.0000315194 PSNR_train: 29.1831\n",
      "[epoch 154][250/250] loss: 0.0000342093 PSNR_train: 28.9233\n",
      "\n",
      "[epoch 154] PSNR_test: 23.3243\n",
      "[epoch 155][50/250] loss: 0.0000280065 PSNR_train: 29.6571\n",
      "[epoch 155][100/250] loss: 0.0000328143 PSNR_train: 29.0855\n",
      "[epoch 155][150/250] loss: 0.0000325237 PSNR_train: 29.2418\n",
      "[epoch 155][200/250] loss: 0.0000338110 PSNR_train: 28.8700\n",
      "[epoch 155][250/250] loss: 0.0000329458 PSNR_train: 28.9624\n",
      "\n",
      "[epoch 155] PSNR_test: 23.2748\n",
      "[epoch 156][50/250] loss: 0.0000314837 PSNR_train: 29.1239\n",
      "[epoch 156][100/250] loss: 0.0000294753 PSNR_train: 29.4137\n",
      "[epoch 156][150/250] loss: 0.0000334758 PSNR_train: 29.0342\n",
      "[epoch 156][200/250] loss: 0.0000264838 PSNR_train: 30.0040\n",
      "[epoch 156][250/250] loss: 0.0000339103 PSNR_train: 28.9947\n",
      "\n",
      "[epoch 156] PSNR_test: 23.2941\n",
      "[epoch 157][50/250] loss: 0.0000317307 PSNR_train: 29.1053\n",
      "[epoch 157][100/250] loss: 0.0000294825 PSNR_train: 29.4695\n",
      "[epoch 157][150/250] loss: 0.0000304010 PSNR_train: 29.3611\n",
      "[epoch 157][200/250] loss: 0.0000314254 PSNR_train: 29.2809\n",
      "[epoch 157][250/250] loss: 0.0000371623 PSNR_train: 28.5562\n",
      "\n",
      "[epoch 157] PSNR_test: 23.2961\n",
      "[epoch 158][50/250] loss: 0.0000307809 PSNR_train: 29.3955\n",
      "[epoch 158][100/250] loss: 0.0000278179 PSNR_train: 29.6472\n",
      "[epoch 158][150/250] loss: 0.0000317073 PSNR_train: 29.1162\n",
      "[epoch 158][200/250] loss: 0.0000292860 PSNR_train: 29.5133\n",
      "[epoch 158][250/250] loss: 0.0000297436 PSNR_train: 29.5541\n",
      "\n",
      "[epoch 158] PSNR_test: 23.2974\n",
      "[epoch 159][50/250] loss: 0.0000312801 PSNR_train: 29.1889\n",
      "[epoch 159][100/250] loss: 0.0000279054 PSNR_train: 29.7860\n",
      "[epoch 159][150/250] loss: 0.0000337103 PSNR_train: 28.8101\n",
      "[epoch 159][200/250] loss: 0.0000314061 PSNR_train: 29.1929\n",
      "[epoch 159][250/250] loss: 0.0000306706 PSNR_train: 29.3990\n",
      "\n",
      "[epoch 159] PSNR_test: 23.3064\n",
      "[epoch 160][50/250] loss: 0.0000302385 PSNR_train: 29.5350\n",
      "[epoch 160][100/250] loss: 0.0000266652 PSNR_train: 29.9225\n",
      "[epoch 160][150/250] loss: 0.0000347567 PSNR_train: 28.8698\n",
      "[epoch 160][200/250] loss: 0.0000291300 PSNR_train: 29.4824\n",
      "[epoch 160][250/250] loss: 0.0000324622 PSNR_train: 28.9938\n",
      "\n",
      "[epoch 160] PSNR_test: 23.2947\n",
      "[epoch 161][50/250] loss: 0.0000313283 PSNR_train: 29.1888\n",
      "[epoch 161][100/250] loss: 0.0000320774 PSNR_train: 29.0738\n",
      "[epoch 161][150/250] loss: 0.0000348311 PSNR_train: 28.7782\n",
      "[epoch 161][200/250] loss: 0.0000290902 PSNR_train: 29.6093\n",
      "[epoch 161][250/250] loss: 0.0000341184 PSNR_train: 29.0185\n",
      "\n",
      "[epoch 161] PSNR_test: 23.2706\n",
      "[epoch 162][50/250] loss: 0.0000307351 PSNR_train: 29.2869\n",
      "[epoch 162][100/250] loss: 0.0000277706 PSNR_train: 29.7778\n",
      "[epoch 162][150/250] loss: 0.0000349786 PSNR_train: 28.7546\n",
      "[epoch 162][200/250] loss: 0.0000310823 PSNR_train: 29.3056\n",
      "[epoch 162][250/250] loss: 0.0000311974 PSNR_train: 29.3749\n",
      "\n",
      "[epoch 162] PSNR_test: 23.2079\n",
      "[epoch 163][50/250] loss: 0.0000266879 PSNR_train: 29.9939\n",
      "[epoch 163][100/250] loss: 0.0000318098 PSNR_train: 29.1638\n",
      "[epoch 163][150/250] loss: 0.0000285256 PSNR_train: 29.7612\n",
      "[epoch 163][200/250] loss: 0.0000338026 PSNR_train: 28.9708\n",
      "[epoch 163][250/250] loss: 0.0000290813 PSNR_train: 29.4727\n",
      "\n",
      "[epoch 163] PSNR_test: 23.2663\n",
      "[epoch 164][50/250] loss: 0.0000334838 PSNR_train: 28.9524\n",
      "[epoch 164][100/250] loss: 0.0000329108 PSNR_train: 28.9963\n",
      "[epoch 164][150/250] loss: 0.0000355942 PSNR_train: 28.6033\n",
      "[epoch 164][200/250] loss: 0.0000368595 PSNR_train: 28.4524\n",
      "[epoch 164][250/250] loss: 0.0000318677 PSNR_train: 29.0901\n",
      "\n",
      "[epoch 164] PSNR_test: 23.2493\n",
      "[epoch 165][50/250] loss: 0.0000286251 PSNR_train: 29.5433\n",
      "[epoch 165][100/250] loss: 0.0000293971 PSNR_train: 29.5106\n",
      "[epoch 165][150/250] loss: 0.0000292238 PSNR_train: 29.5341\n",
      "[epoch 165][200/250] loss: 0.0000328573 PSNR_train: 29.0982\n",
      "[epoch 165][250/250] loss: 0.0000312881 PSNR_train: 29.3114\n",
      "\n",
      "[epoch 165] PSNR_test: 23.2996\n",
      "[epoch 166][50/250] loss: 0.0000343190 PSNR_train: 28.7674\n",
      "[epoch 166][100/250] loss: 0.0000285296 PSNR_train: 29.5976\n",
      "[epoch 166][150/250] loss: 0.0000301239 PSNR_train: 29.4339\n",
      "[epoch 166][200/250] loss: 0.0000337424 PSNR_train: 28.9417\n",
      "[epoch 166][250/250] loss: 0.0000334653 PSNR_train: 29.0075\n",
      "\n",
      "[epoch 166] PSNR_test: 23.3078\n",
      "[epoch 167][50/250] loss: 0.0000305560 PSNR_train: 29.3512\n",
      "[epoch 167][100/250] loss: 0.0000305999 PSNR_train: 29.2168\n",
      "[epoch 167][150/250] loss: 0.0000304321 PSNR_train: 29.4060\n",
      "[epoch 167][200/250] loss: 0.0000301617 PSNR_train: 29.4040\n",
      "[epoch 167][250/250] loss: 0.0000337946 PSNR_train: 28.9400\n",
      "\n",
      "[epoch 167] PSNR_test: 23.2419\n",
      "[epoch 168][50/250] loss: 0.0000296704 PSNR_train: 29.4308\n",
      "[epoch 168][100/250] loss: 0.0000303462 PSNR_train: 29.3461\n",
      "[epoch 168][150/250] loss: 0.0000343369 PSNR_train: 28.8848\n",
      "[epoch 168][200/250] loss: 0.0000312918 PSNR_train: 29.2194\n",
      "[epoch 168][250/250] loss: 0.0000358963 PSNR_train: 28.5574\n",
      "\n",
      "[epoch 168] PSNR_test: 23.2456\n",
      "[epoch 169][50/250] loss: 0.0000304648 PSNR_train: 29.3767\n",
      "[epoch 169][100/250] loss: 0.0000354704 PSNR_train: 28.6575\n",
      "[epoch 169][150/250] loss: 0.0000306876 PSNR_train: 29.2518\n",
      "[epoch 169][200/250] loss: 0.0000354346 PSNR_train: 28.5901\n",
      "[epoch 169][250/250] loss: 0.0000317257 PSNR_train: 29.0761\n",
      "\n",
      "[epoch 169] PSNR_test: 23.2880\n",
      "[epoch 170][50/250] loss: 0.0000283296 PSNR_train: 29.7206\n",
      "[epoch 170][100/250] loss: 0.0000296285 PSNR_train: 29.3855\n",
      "[epoch 170][150/250] loss: 0.0000318974 PSNR_train: 29.1247\n",
      "[epoch 170][200/250] loss: 0.0000316462 PSNR_train: 29.1758\n",
      "[epoch 170][250/250] loss: 0.0000327105 PSNR_train: 28.9780\n",
      "\n",
      "[epoch 170] PSNR_test: 23.3348\n",
      "[epoch 171][50/250] loss: 0.0000289542 PSNR_train: 29.5411\n",
      "[epoch 171][100/250] loss: 0.0000276085 PSNR_train: 29.7209\n",
      "[epoch 171][150/250] loss: 0.0000341607 PSNR_train: 28.8305\n",
      "[epoch 171][200/250] loss: 0.0000305813 PSNR_train: 29.3402\n",
      "[epoch 171][250/250] loss: 0.0000349587 PSNR_train: 28.7077\n",
      "\n",
      "[epoch 171] PSNR_test: 23.1571\n",
      "[epoch 172][50/250] loss: 0.0000310298 PSNR_train: 29.3214\n",
      "[epoch 172][100/250] loss: 0.0000318007 PSNR_train: 29.0789\n",
      "[epoch 172][150/250] loss: 0.0000388481 PSNR_train: 28.2255\n",
      "[epoch 172][200/250] loss: 0.0000283851 PSNR_train: 29.5621\n",
      "[epoch 172][250/250] loss: 0.0000300734 PSNR_train: 29.4230\n",
      "\n",
      "[epoch 172] PSNR_test: 23.2345\n",
      "[epoch 173][50/250] loss: 0.0000339541 PSNR_train: 28.7848\n",
      "[epoch 173][100/250] loss: 0.0000282812 PSNR_train: 29.6740\n",
      "[epoch 173][150/250] loss: 0.0000294538 PSNR_train: 29.6702\n",
      "[epoch 173][200/250] loss: 0.0000313587 PSNR_train: 29.1391\n",
      "[epoch 173][250/250] loss: 0.0000320422 PSNR_train: 29.1532\n",
      "\n",
      "[epoch 173] PSNR_test: 23.2680\n",
      "[epoch 174][50/250] loss: 0.0000276371 PSNR_train: 29.9109\n",
      "[epoch 174][100/250] loss: 0.0000247509 PSNR_train: 30.5138\n",
      "[epoch 174][150/250] loss: 0.0000282156 PSNR_train: 29.7622\n",
      "[epoch 174][200/250] loss: 0.0000347346 PSNR_train: 28.8426\n",
      "[epoch 174][250/250] loss: 0.0000318240 PSNR_train: 29.2462\n",
      "\n",
      "[epoch 174] PSNR_test: 23.1972\n",
      "[epoch 175][50/250] loss: 0.0000297650 PSNR_train: 29.3561\n",
      "[epoch 175][100/250] loss: 0.0000280800 PSNR_train: 29.7766\n",
      "[epoch 175][150/250] loss: 0.0000306892 PSNR_train: 29.3475\n",
      "[epoch 175][200/250] loss: 0.0000328423 PSNR_train: 29.0863\n",
      "[epoch 175][250/250] loss: 0.0000315517 PSNR_train: 29.1463\n",
      "\n",
      "[epoch 175] PSNR_test: 23.2382\n",
      "[epoch 176][50/250] loss: 0.0000333513 PSNR_train: 28.9284\n",
      "[epoch 176][100/250] loss: 0.0000307328 PSNR_train: 29.2524\n",
      "[epoch 176][150/250] loss: 0.0000314148 PSNR_train: 29.2717\n",
      "[epoch 176][200/250] loss: 0.0000292944 PSNR_train: 29.4668\n",
      "[epoch 176][250/250] loss: 0.0000314446 PSNR_train: 29.2303\n",
      "\n",
      "[epoch 176] PSNR_test: 23.3041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 177][50/250] loss: 0.0000285530 PSNR_train: 29.6225\n",
      "[epoch 177][100/250] loss: 0.0000394149 PSNR_train: 28.4045\n",
      "[epoch 177][150/250] loss: 0.0000292690 PSNR_train: 29.4502\n",
      "[epoch 177][200/250] loss: 0.0000288895 PSNR_train: 29.5927\n",
      "[epoch 177][250/250] loss: 0.0000327503 PSNR_train: 29.0922\n",
      "\n",
      "[epoch 177] PSNR_test: 23.1560\n",
      "[epoch 178][50/250] loss: 0.0000302675 PSNR_train: 29.2789\n",
      "[epoch 178][100/250] loss: 0.0000302060 PSNR_train: 29.3615\n",
      "[epoch 178][150/250] loss: 0.0000310387 PSNR_train: 29.3025\n",
      "[epoch 178][200/250] loss: 0.0000299252 PSNR_train: 29.3310\n",
      "[epoch 178][250/250] loss: 0.0000304901 PSNR_train: 29.2241\n",
      "\n",
      "[epoch 178] PSNR_test: 23.2849\n",
      "[epoch 179][50/250] loss: 0.0000298492 PSNR_train: 29.4998\n",
      "[epoch 179][100/250] loss: 0.0000309904 PSNR_train: 29.2954\n",
      "[epoch 179][150/250] loss: 0.0000333204 PSNR_train: 28.8438\n",
      "[epoch 179][200/250] loss: 0.0000331716 PSNR_train: 28.9264\n",
      "[epoch 179][250/250] loss: 0.0000304102 PSNR_train: 29.2731\n",
      "\n",
      "[epoch 179] PSNR_test: 23.2737\n",
      "[epoch 180][50/250] loss: 0.0000290269 PSNR_train: 29.4947\n",
      "[epoch 180][100/250] loss: 0.0000342682 PSNR_train: 28.7872\n",
      "[epoch 180][150/250] loss: 0.0000385087 PSNR_train: 28.2833\n",
      "[epoch 180][200/250] loss: 0.0000311373 PSNR_train: 29.3352\n",
      "[epoch 180][250/250] loss: 0.0000346331 PSNR_train: 28.7041\n",
      "\n",
      "[epoch 180] PSNR_test: 23.2169\n",
      "[epoch 181][50/250] loss: 0.0000298586 PSNR_train: 29.4455\n",
      "[epoch 181][100/250] loss: 0.0000301383 PSNR_train: 29.4282\n",
      "[epoch 181][150/250] loss: 0.0000341089 PSNR_train: 28.7900\n",
      "[epoch 181][200/250] loss: 0.0000323564 PSNR_train: 29.0193\n",
      "[epoch 181][250/250] loss: 0.0000358987 PSNR_train: 28.6043\n",
      "\n",
      "[epoch 181] PSNR_test: 23.2272\n",
      "[epoch 182][50/250] loss: 0.0000305176 PSNR_train: 29.2185\n",
      "[epoch 182][100/250] loss: 0.0000310844 PSNR_train: 29.2051\n",
      "[epoch 182][150/250] loss: 0.0000275549 PSNR_train: 29.8074\n",
      "[epoch 182][200/250] loss: 0.0000330381 PSNR_train: 29.0493\n",
      "[epoch 182][250/250] loss: 0.0000328080 PSNR_train: 28.9953\n",
      "\n",
      "[epoch 182] PSNR_test: 23.1952\n",
      "[epoch 183][50/250] loss: 0.0000340571 PSNR_train: 28.8545\n",
      "[epoch 183][100/250] loss: 0.0000295570 PSNR_train: 29.6578\n",
      "[epoch 183][150/250] loss: 0.0000292700 PSNR_train: 29.4857\n",
      "[epoch 183][200/250] loss: 0.0000284958 PSNR_train: 29.7165\n",
      "[epoch 183][250/250] loss: 0.0000302325 PSNR_train: 29.3145\n",
      "\n",
      "[epoch 183] PSNR_test: 23.2613\n",
      "[epoch 184][50/250] loss: 0.0000265602 PSNR_train: 29.9741\n",
      "[epoch 184][100/250] loss: 0.0000305610 PSNR_train: 29.3555\n",
      "[epoch 184][150/250] loss: 0.0000298240 PSNR_train: 29.5979\n",
      "[epoch 184][200/250] loss: 0.0000287788 PSNR_train: 29.6078\n",
      "[epoch 184][250/250] loss: 0.0000313477 PSNR_train: 29.2372\n",
      "\n",
      "[epoch 184] PSNR_test: 23.2627\n",
      "[epoch 185][50/250] loss: 0.0000295298 PSNR_train: 29.4263\n",
      "[epoch 185][100/250] loss: 0.0000295836 PSNR_train: 29.5708\n",
      "[epoch 185][150/250] loss: 0.0000291071 PSNR_train: 29.4636\n",
      "[epoch 185][200/250] loss: 0.0000313418 PSNR_train: 29.2101\n",
      "[epoch 185][250/250] loss: 0.0000297228 PSNR_train: 29.4622\n",
      "\n",
      "[epoch 185] PSNR_test: 23.2419\n",
      "[epoch 186][50/250] loss: 0.0000324704 PSNR_train: 29.0411\n",
      "[epoch 186][100/250] loss: 0.0000305480 PSNR_train: 29.3924\n",
      "[epoch 186][150/250] loss: 0.0000279719 PSNR_train: 29.7611\n",
      "[epoch 186][200/250] loss: 0.0000323344 PSNR_train: 29.0473\n",
      "[epoch 186][250/250] loss: 0.0000329653 PSNR_train: 29.0402\n",
      "\n",
      "[epoch 186] PSNR_test: 23.2324\n",
      "[epoch 187][50/250] loss: 0.0000331679 PSNR_train: 29.0008\n",
      "[epoch 187][100/250] loss: 0.0000330679 PSNR_train: 28.9850\n",
      "[epoch 187][150/250] loss: 0.0000294522 PSNR_train: 29.5735\n",
      "[epoch 187][200/250] loss: 0.0000331231 PSNR_train: 28.9169\n",
      "[epoch 187][250/250] loss: 0.0000331780 PSNR_train: 29.0225\n",
      "\n",
      "[epoch 187] PSNR_test: 23.2123\n",
      "[epoch 188][50/250] loss: 0.0000307190 PSNR_train: 29.2033\n",
      "[epoch 188][100/250] loss: 0.0000295774 PSNR_train: 29.5019\n",
      "[epoch 188][150/250] loss: 0.0000338808 PSNR_train: 28.9156\n",
      "[epoch 188][200/250] loss: 0.0000321408 PSNR_train: 29.1933\n",
      "[epoch 188][250/250] loss: 0.0000330496 PSNR_train: 29.0456\n",
      "\n",
      "[epoch 188] PSNR_test: 23.2310\n",
      "[epoch 189][50/250] loss: 0.0000275471 PSNR_train: 29.7617\n",
      "[epoch 189][100/250] loss: 0.0000280060 PSNR_train: 29.7639\n",
      "[epoch 189][150/250] loss: 0.0000276288 PSNR_train: 29.7251\n",
      "[epoch 189][200/250] loss: 0.0000257567 PSNR_train: 30.0145\n",
      "[epoch 189][250/250] loss: 0.0000331521 PSNR_train: 28.8624\n",
      "\n",
      "[epoch 189] PSNR_test: 23.2833\n",
      "[epoch 190][50/250] loss: 0.0000298498 PSNR_train: 29.3877\n",
      "[epoch 190][100/250] loss: 0.0000296921 PSNR_train: 29.4312\n",
      "[epoch 190][150/250] loss: 0.0000253013 PSNR_train: 30.2005\n",
      "[epoch 190][200/250] loss: 0.0000310297 PSNR_train: 29.1485\n",
      "[epoch 190][250/250] loss: 0.0000293679 PSNR_train: 29.5494\n",
      "\n",
      "[epoch 190] PSNR_test: 23.2171\n",
      "[epoch 191][50/250] loss: 0.0000297886 PSNR_train: 29.3357\n",
      "[epoch 191][100/250] loss: 0.0000250170 PSNR_train: 30.1556\n",
      "[epoch 191][150/250] loss: 0.0000320528 PSNR_train: 29.1972\n",
      "[epoch 191][200/250] loss: 0.0000336034 PSNR_train: 28.8389\n",
      "[epoch 191][250/250] loss: 0.0000309617 PSNR_train: 29.2107\n",
      "\n",
      "[epoch 191] PSNR_test: 23.2845\n",
      "[epoch 192][50/250] loss: 0.0000260845 PSNR_train: 30.0262\n",
      "[epoch 192][100/250] loss: 0.0000303038 PSNR_train: 29.3938\n",
      "[epoch 192][150/250] loss: 0.0000290188 PSNR_train: 29.6121\n",
      "[epoch 192][200/250] loss: 0.0000294589 PSNR_train: 29.5277\n",
      "[epoch 192][250/250] loss: 0.0000284033 PSNR_train: 29.5805\n",
      "\n",
      "[epoch 192] PSNR_test: 23.2279\n",
      "[epoch 193][50/250] loss: 0.0000315279 PSNR_train: 29.1671\n",
      "[epoch 193][100/250] loss: 0.0000331945 PSNR_train: 29.0325\n",
      "[epoch 193][150/250] loss: 0.0000328886 PSNR_train: 29.0608\n",
      "[epoch 193][200/250] loss: 0.0000314177 PSNR_train: 29.1465\n",
      "[epoch 193][250/250] loss: 0.0000294678 PSNR_train: 29.5442\n",
      "\n",
      "[epoch 193] PSNR_test: 23.1572\n",
      "[epoch 194][50/250] loss: 0.0000277024 PSNR_train: 29.7224\n",
      "[epoch 194][100/250] loss: 0.0000269664 PSNR_train: 29.7996\n",
      "[epoch 194][150/250] loss: 0.0000284599 PSNR_train: 29.6133\n",
      "[epoch 194][200/250] loss: 0.0000307293 PSNR_train: 29.3128\n",
      "[epoch 194][250/250] loss: 0.0000290528 PSNR_train: 29.7920\n",
      "\n",
      "[epoch 194] PSNR_test: 23.1978\n",
      "[epoch 195][50/250] loss: 0.0000277574 PSNR_train: 29.7451\n",
      "[epoch 195][100/250] loss: 0.0000357322 PSNR_train: 28.5775\n",
      "[epoch 195][150/250] loss: 0.0000273339 PSNR_train: 29.8044\n",
      "[epoch 195][200/250] loss: 0.0000316471 PSNR_train: 29.2054\n",
      "[epoch 195][250/250] loss: 0.0000300612 PSNR_train: 29.3228\n",
      "\n",
      "[epoch 195] PSNR_test: 23.2272\n",
      "[epoch 196][50/250] loss: 0.0000311433 PSNR_train: 29.1301\n",
      "[epoch 196][100/250] loss: 0.0000313807 PSNR_train: 29.1225\n",
      "[epoch 196][150/250] loss: 0.0000298488 PSNR_train: 29.3246\n",
      "[epoch 196][200/250] loss: 0.0000295474 PSNR_train: 29.5427\n",
      "[epoch 196][250/250] loss: 0.0000310806 PSNR_train: 29.3104\n",
      "\n",
      "[epoch 196] PSNR_test: 23.2077\n",
      "[epoch 197][50/250] loss: 0.0000284302 PSNR_train: 29.5979\n",
      "[epoch 197][100/250] loss: 0.0000331496 PSNR_train: 28.8636\n",
      "[epoch 197][150/250] loss: 0.0000304756 PSNR_train: 29.2881\n",
      "[epoch 197][200/250] loss: 0.0000324992 PSNR_train: 29.1328\n",
      "[epoch 197][250/250] loss: 0.0000325173 PSNR_train: 28.9809\n",
      "\n",
      "[epoch 197] PSNR_test: 23.1515\n",
      "[epoch 198][50/250] loss: 0.0000248918 PSNR_train: 30.2599\n",
      "[epoch 198][100/250] loss: 0.0000255356 PSNR_train: 30.1303\n",
      "[epoch 198][150/250] loss: 0.0000351388 PSNR_train: 28.6073\n",
      "[epoch 198][200/250] loss: 0.0000305405 PSNR_train: 29.3023\n",
      "[epoch 198][250/250] loss: 0.0000304573 PSNR_train: 29.3151\n",
      "\n",
      "[epoch 198] PSNR_test: 23.2393\n",
      "[epoch 199][50/250] loss: 0.0000251959 PSNR_train: 30.2381\n",
      "[epoch 199][100/250] loss: 0.0000329576 PSNR_train: 28.9376\n",
      "[epoch 199][150/250] loss: 0.0000306286 PSNR_train: 29.2799\n",
      "[epoch 199][200/250] loss: 0.0000292359 PSNR_train: 29.4359\n",
      "[epoch 199][250/250] loss: 0.0000299207 PSNR_train: 29.4577\n",
      "\n",
      "[epoch 199] PSNR_test: 23.2429\n",
      "[epoch 200][50/250] loss: 0.0000281340 PSNR_train: 29.7398\n",
      "[epoch 200][100/250] loss: 0.0000295778 PSNR_train: 29.4756\n",
      "[epoch 200][150/250] loss: 0.0000307050 PSNR_train: 29.3707\n",
      "[epoch 200][200/250] loss: 0.0000311764 PSNR_train: 29.3005\n",
      "[epoch 200][250/250] loss: 0.0000307679 PSNR_train: 29.2397\n",
      "\n",
      "[epoch 200] PSNR_test: 23.1823\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    #milestone\n",
    "    if epoch>800:\n",
    "        current_lr=lr/100.\n",
    "    elif epoch>500:\n",
    "        current_lr=lr/10.\n",
    "    else:\n",
    "        current_lr=lr\n",
    "    \n",
    "    for i, batch in enumerate(training_data_loader,1):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #obtain a batch of data and label\n",
    "        data, target = Variable(batch[0]), Variable(batch[1], requires_grad=False)\n",
    "        data=data.cuda()\n",
    "        target = target.cuda()\n",
    "        \n",
    "        #input the data to the CNN\n",
    "        out=model(data)\n",
    "        \n",
    "        #calculate the loss between the network output and label using MSE function\n",
    "        loss=criterion(out,target)/(batchSize*2)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "        model.eval()\n",
    "        \n",
    "        #show the PSNR of the training data until now\n",
    "        if i % print_every == 0:\n",
    "            out_np=ts_to_np(out)\n",
    "            target_np=ts_to_np(target)\n",
    "    \n",
    "            psnr_train=batch_psnr(out_np,target_np)\n",
    "            print(\"[epoch %d][%d/%d] loss: %.10f PSNR_train: %.4f\" % (epoch, i,len(training_data_loader), loss.item(), psnr_train))\n",
    "    \n",
    "    #save the loss value at this epoch    \n",
    "    plot_loss_save(epoch,iters,y_loss,loss)       \n",
    "#     torch.save(model.state_dict(), os.path.join(model_path, 'CNN_{}.pth'.format(epoch+1)))\n",
    "    \n",
    "        \n",
    "    #verify the model efficiency with the trained model   \n",
    "    model.eval() \n",
    "    psnr_test=0\n",
    "    for i, batch in enumerate(testing_data_loader):\n",
    "        data, target = Variable(batch[0]),Variable(batch[1], requires_grad=False)\n",
    "        \n",
    "        out_test=model(data.cuda())\n",
    "        #print(out_val.shape)\n",
    "        out_test_np=ts_to_np(out_test)\n",
    "       \n",
    "        target_np=ts_to_np(target)\n",
    "      \n",
    "        psnr_test+=batch_psnr(out_test_np,target_np)\n",
    "        \n",
    "            \n",
    "    psnr_test /= len(testing_data_loader)\n",
    "    print(\"\\n[epoch %d] PSNR_test: %.4f\" % (epoch, psnr_test))\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(model_path, 'CNN_{}.pth'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755bd477",
   "metadata": {},
   "source": [
    "Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32ec0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2IUlEQVR4nO3dd3gVVf7H8fc3nZBQAwKCFOkgAqJiRQQLrgULP8u6a1uVVaxbZNfVxbIqthVcG1asqKuruKKiqICwIL0JSOiR0BJaCOnf3x/3JqYnhNwEzOf1PHnu3DNz5p6ZXPLhzJli7o6IiEh1CKvtBoiIyC+HQkVERKqNQkVERKqNQkVERKqNQkVERKqNQkVERKqNQkWkBpnZOjMbXNvtEAkVhYqIiFQbhYqIiFQbhYpILTCzaDN7ysw2BX+eMrPo4LwEM/uvme00s1Qzm25mYcF5d5nZT2a2x8xWmtmg2t0SkaIiarsBInXU3UB/oDfgwMfA34B7gD8ASUCz4LL9ATezLsAI4Fh332Rm7YDwmm22SPnUUxGpHb8G7nf3re6+DbgP+E1wXjbQEmjr7tnuPt0DN+nLBaKB7mYW6e7r3H11rbRepAwKFZHa0QpYX+j9+mAZwGNAIjDZzNaY2UgAd08EbgdGAVvNbIKZtULkIKJQEakdm4C2hd4fESzD3fe4+x/cvQNwHnBn/tiJu7/t7icH6zowumabLVI+hYpI7XgH+JuZNTOzBOBe4E0AMzvXzDqamQG7CRz2yjWzLmZ2enBAPwPYF5wnctBQqIjUjgeBucBiYAkwP1gG0An4CkgD/gc86+7fEhhPeQTYDmwGmgN/rdFWi1TA9JAuERGpLuqpiIhItVGoiIhItVGoiIhItVGoiIhItQnpbVrM7GxgDIFbSbzk7o8Um2/B+ecA6cDV7j6/vLpm1gR4F2gHrAP+z913BG9ZsRxYGVz9LHcfXl77EhISvF27dge8nSIidcm8efO2u3uz0uaFLFTMLBx4BjiDwH2M5pjZRHf/odBiQwicPtkJOB54Dji+grojgSnu/kjwSuORwF3B9a12996VbWO7du2YO3fugWymiEidY2bry5oXysNfxwGJ7r7G3bOACcAFxZa5AHjdA2YBjcysZQV1LwDGB6fHA0NDuA0iIrIfQhkqhwMbC71PCpZVZpny6h7m7skAwdfmhZZrb2YLzGyqmZ1SWqPM7AYzm2tmc7dt27a/2yQiIuUIZahYKWXFr7Qsa5nK1C0uGTjC3fsAdwJvm1mDEitxH+fu/dy9X7NmpR4SFBGRKgrlQH0S0KbQ+9YEb5hXiWWiyqm7xcxaunty8FDZVgB3zwQyg9PzzGw10JnArTBEpA7Kzs4mKSmJjIyM2m7KISkmJobWrVsTGRlZ6TqhDJU5QCczaw/8BFwGXFFsmYnACDObQGCgflcwLLaVU3cicBWBeyBdReDhRphZMyDV3XPNrAOBwf81Idw+ETnIJSUlER8fT7t27QicbCqV5e6kpKSQlJRE+/btK10vZKHi7jlmNgL4gsBpwa+4+zIzGx6c/zwwicDpxIkETim+pry6wVU/ArxnZtcBG4BhwfJTgfvNLIfAnVuHu3tqqLZPRA5+GRkZCpQqMjOaNm3K/o49h/Q6FXefRCA4Cpc9X2jagZsrWzdYngKUeC63u38AfHCATRaRXxgFStVVZd/pivoqSNqdxL3f3MuPKT/WdlNERA4qCpUq2Jy2mQemPaBQEZEKxcXF1XYTCjz11FOkp6eH9DMUKlUQERY4apidm13LLRER+Zm7k5eXV+Z8hcpBKj9UcvJyarklInIoWrhwIf3796dXr15ceOGF7NixA4CxY8fSvXt3evXqxWWXXQbA1KlT6d27N71796ZPnz7s2bOnyLrWrVtHt27duOmmm+jbty8bN27k97//Pf369aNHjx78/e9/L1j3pk2bGDhwIAMHDgRg8uTJnHDCCfTt25dhw4aRlpZ2wNtWp5/82K9fP6/Kvb9Wbl9J12e68vZFb3P5UZeHoGUiUh2WL19Ot27dALj989tZuHlhta6/d4vePHX2U+UuExcXV+KPda9evXj66acZMGAA9957L7t37+app56iVatWrF27lujoaHbu3EmjRo0477zzGDlyJCeddBJpaWnExMQQEfHzOVbr1q2jQ4cOzJw5k/79+wOQmppKkyZNyM3NZdCgQYwdO5ZevXoV3O8wISGB7du3c9FFF/HZZ59Rv359Ro8eTWZmJvfee2+Rthbeh/nMbJ679ytte9VTqYKCw195OvwlIvtn165d7Ny5kwEDBgBw1VVXMW3aNCAQNr/+9a958803C4LjpJNO4s4772Ts2LHs3LmzSKDka9u2bUGgALz33nv07duXPn36sGzZMn744YcSdWbNmsUPP/zASSedRO/evRk/fjzr15d5n8hKC+kpxb9UkeGBq0t1+Evk0FFRj+Jg8OmnnzJt2jQmTpzIAw88wLJlyxg5ciS/+tWvmDRpEv379+err76ia9euRerVr1+/YHrt2rU8/vjjzJkzh8aNG3P11VeXekcBd+eMM87gnXfeqdZtUE+lCjRQLyJV1bBhQxo3bsz06dMBeOONNxgwYAB5eXls3LiRgQMH8uijj7Jz507S0tJYvXo1Rx11FHfddRf9+vVjxYoV5a5/9+7d1K9fn4YNG7JlyxY+++yzgnnx8fEFYzL9+/dnxowZJCYmApCens6PPx74Ga3qqVSBBupFpLLS09Np3bp1wfs777yT8ePHM3z4cNLT0+nQoQOvvvoqubm5XHnllezatQt354477qBRo0bcc889fPPNN4SHh9O9e3eGDBlS7ucdffTR9OnThx49etChQwdOOumkgnk33HADQ4YMoWXLlnzzzTe89tprXH755WRmZgLw4IMP0rlz5wPaXg3UV2Ggfse+HTR5tAlPnfUUt/W/LQQtE5HqUNogs+wfDdTXAA3Ui4iUTqFSBRqoFxEpnUKlCjSmInLoqMuH+A9UVfadQqUKwi0c0NlfIge7mJgYUlJSFCxVkP88lZiYmP2qp7O/qsDMiAiLUE9F5CDXunVrkpKS9vuZIBKQ/+TH/aFQqaKIsAgN1Isc5CIjI/frqYVy4HT4q4oiwyLVUxERKUahUkU6/CUiUpJCpYoiwiI0UC8iUoxCpYoiw3X4S0SkOIVKFWmgXkSkJIVKFWlMRUSkJIVKFensLxGRkhQqVaTDXyIiJSlUqkgD9SIiJSlUqkinFIuIlKRQqSIN1IuIlKRQqSIN1IuIlKRQqSIN1IuIlKRQqSIN1IuIlKRQqSKNqYiIlKRQqSKd/SUiUpJCpYo0UC8iUpJCpYo0UC8iUlJIQ8XMzjazlWaWaGYjS5lvZjY2OH+xmfWtqK6ZNTGzL81sVfC1cbF1HmFmaWb2x1BumwbqRURKClmomFk48AwwBOgOXG5m3YstNgToFPy5AXiuEnVHAlPcvRMwJfi+sH8Cn1X7BhWjgXoRkZJC2VM5Dkh09zXungVMAC4otswFwOseMAtoZGYtK6h7ATA+OD0eGJq/MjMbCqwBloVmk34WYRqoFxEpLpShcjiwsdD7pGBZZZYpr+5h7p4MEHxtDmBm9YG7gPuqqf3l0uEvEZGSQhkqVkqZV3KZytQt7j7gn+6eVm6jzG4ws7lmNnfbtm0VrLJsGqgXESkpIoTrTgLaFHrfGthUyWWiyqm7xcxaunty8FDZ1mD58cAlZvYo0AjIM7MMd/9X4Q9093HAOIB+/fpVFFRl0piKiEhJoeypzAE6mVl7M4sCLgMmFltmIvDb4Flg/YFdwUNa5dWdCFwVnL4K+BjA3U9x93bu3g54CnioeKBUJ12nIiJSUsh6Ku6eY2YjgC+AcOAVd19mZsOD858HJgHnAIlAOnBNeXWDq34EeM/MrgM2AMNCtQ3l0RX1IiIlhfLwF+4+iUBwFC57vtC0AzdXtm6wPAUYVMHnjqpCc/dLZHgkuZ6Lu2NW2hCQiEjdoyvqqygiLJDHOgQmIvIzhUoVKVREREpSqFRRZFgkoFARESlMoVJF+T0VXasiIvIzhUoVRYarpyIiUpxCpYoKeio6rVhEpIBCpYo0UC8iUpJCpYo0UC8iUpJCpYo0UC8iUpJCpYo0UC8iUpJCpYo0piIiUpJCpYp09peISEkKlSrSQL2ISEkKlSrSQL2ISEkKlSrSmIqISEkKlSrS2V8iIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKpIA/UiIiUpVKooPCwc0EC9iEhhCpUqCrMwwixMPRURkUIUKgcgMixSoSIiUohC5QBEhEVooF5EpBCFygGICItQT0VEpBCFygGIDNfhLxGRwhQqByAiLEJnf4mIFBLSUDGzs81spZklmtnIUuabmY0Nzl9sZn0rqmtmTczsSzNbFXxtHCw/zswWBn8WmdmFodw20EC9iEhxIQsVMwsHngGGAN2By82se7HFhgCdgj83AM9Vou5IYIq7dwKmBN8DLAX6uXtv4GzgBTOLCM3WBainIiJSVCh7KscBie6+xt2zgAnABcWWuQB43QNmAY3MrGUFdS8AxgenxwNDAdw93d3zuw0xgIdouwpooF5EpKhQhsrhwMZC75OCZZVZpry6h7l7MkDwtXn+QmZ2vJktA5YAwwuFDIWWucHM5prZ3G3btlVpw/JpoF5EpKhQhoqVUla891DWMpWpW3IB99nu3gM4FviLmcWUssw4d+/n7v2aNWtW0SrLpetURESKCmWoJAFtCr1vDWyq5DLl1d0SPERG8HVr8Q929+XAXqDnAbS/QhqoFxEpKpShMgfoZGbtzSwKuAyYWGyZicBvg2eB9Qd2BQ9plVd3InBVcPoq4GOA4LIRwem2QBdgXci2Dg3Ui4gUF7Kzo9w9x8xGAF8A4cAr7r7MzIYH5z8PTALOARKBdOCa8uoGV/0I8J6ZXQdsAIYFy08GRppZNpAH3OTu20O1faCBehGR4kJ6yq27TyIQHIXLni807cDNla0bLE8BBpVS/gbwxgE2eb9ooF5EpChdUX8ANFAvIlKUQuUAaKBeRKQohcoB0EC9iEhRCpUDEBkeSVZuVm03Q0TkoKFQOQD1I+uTnp1e280QETlolBsqZnZloemTis0bEapGHSriouJIy0oDIM/zyM3LreUWiYjUrop6KncWmn662Lxrq7kth5zCofL3b/7OKa+eUsstEhGpXRWFipUxXdr7Oqd+ZH0ycjLIzctlRcoKElMTa7tJIiK1qqJQ8TKmS3tf58RFxQGwN3svezL3aHxFROq8iq6o72pmiwn0So4MThN83yGkLTsE5IdKWlYae7ICoeLumNX5TpyI1FEVhUq3GmnFIapIqGTuwXEycjKoF1mvllsmIlI7yg0Vd19f+L2ZNQVOBTa4+7xQNuxQUD+qPgB7s/ayJ2sPAOnZ6QoVEamzKjql+L9m1jM43ZLAc+CvBd4ws9tD37yDW/GeCqBxFRGp0yoaqG/v7kuD09cAX7r7ecDx6JTiEmMqoFARkbqtolApfGOrQQRvRe/uewg8s6ROyw+V1H2pBbdrUaiISF1W0UD9RjO7hcDjffsCnwOYWT0gMsRtO+jVjwyMqWxO21xQplARkbqsop7KdUAP4GrgUnffGSzvD7waumYdGvJ7KslpyQVlChURqcsqOvtrKzC8lPJvgG9C1ahDhUJFRKSockPFzCaWN9/dz6/e5hxaYiJiCLMwHf4SEQmqaEzlBGAj8A4wG93vqwgzIy4qjuQ96qmIiEDFodICOAO4HLgC+BR4x92Xhbphh4r6kfV1+EtEJKjcgXp3z3X3z939KgKD84nAt8EzwoTAuMrOjJ0F7xUqIlKXVdRTwcyigV8R6K20A8YCH4a2WYeO/MH6fAoVEanLKhqoHw/0BD4D7it0db0EFQ6ViLAIhYqI1GkV9VR+A+wFOgO3FrqluwHu7g1C2LZDQv5NJSPDImkQ3UChIiJ1WkXXqVR0cWSdl99TiY+OJzYylvQchYqI1F0VjqlI+QpCJSqemIgY9VREpE5TqByguMifeyqRYZEKFRGp0xQqByh/TCU+Kp4wC1OoiEidplA5QIXHVNy94LkqIiJ1kQbiD1DhMZXYyFj1VESkTlNP5QAV7qlk5mQqVESkTlOoHKD8B3XFR8UTbuEKFRGp0xQqB6jw4S/QbVpEpG4L6ZiKmZ1tZivNLNHMRpYy38xsbHD+YjPrW1FdM2tiZl+a2arga+Ng+RlmNs/MlgRfTw/ltuXLD5UG0Q00piIidV7IQsXMwoFngCFAd+ByM+tebLEhQKfgzw3Ac5WoOxKY4u6dgCnB9wDbgfPc/SjgKuCNEG1aEcWvqM/KzSInL6cmPlpE5KATyp7KcUCiu69x9yxgAnBBsWUuAF73gFlAIzNrWUHdC4DxwenxwFAAd1/g7puC5cuAmOAdlkOqYUxDABrHNCY2MhaAfdn7Qv2xIiIHpVCGyuEEnhqZLylYVpllyqt7mLsnAwRfm5fy2RcDC9w9s/gMM7vBzOaa2dxt27btx+aUrlOTTky4eAJDuw4tCBUdAhORuiqUoVLao4e9kstUpm7pH2rWAxgN3FjafHcf5+793L1fs2bNKrPKij6PS3teSr3IegoVEanzQhkqSUCbQu9bA5squUx5dbcED5ERfN2av5CZtQb+A/zW3VdXwzbsF4WKiNR1oQyVOUAnM2tvZlHAZcDEYstMBH4bPAusP7AreEirvLoTCQzEE3z9GMDMGgGfAn9x9xkh3K4yKVREpK4L2XUq7p5jZiOAL4Bw4BV3X2Zmw4PznwcmAecAiUA6cE15dYOrfgR4z8yuAzYAw4LlI4COwD1mdk+w7Ex3L+jJhJpCRUTqupBe/OjukwgER+Gy5wtNO3BzZesGy1OAQaWUPwg8eIBNPiAKFRGp63RDyWqkUBGRuk6hUo0UKiJS1ylUqlH+zSX1TBURqasUKtXosLjDqBdRj8TUxNpuiohIrVCoVKMwC6Nbs24s27as4oVFRH6BFCrVrHuz7vyw7YfaboaISK1QqFSzHs16kLQ7iV0Zu2q7KSIiNU6hUs16NOsBoN6KiNRJCpVq1r1Z4LEvChURqYsUKtWsfeP21Iuop8F6EamTFCrVTGeAiUhdplAJAZ0BJiJ1lUIlBNo2bEvynmTyPK+2myIiUqMUKiGQEJtArufqtGIRqXMUKiHQtF5TALanb6/lloiI1CyFSggkxCYAkLIvpZZbIiJSsxQqIZAfKuqpiEhdo1AJAYWKiNRVCpUQaBqrMRURqZsUKiEQHxVPZFgkKen7N6Zy7cfX8ucv/xyiVomIhF5EbTfgl8jMSIhN2O+eytdrv6ZxvcYhapWISOgpVEIkITaB7fsqHyruTnJaMjsyduDumFkIWyciEho6/BUiTWOb7ldPJXVfKlm5WezO3M2OjB0hbJmISOgoVEIkITZhv8ZUktOSC6bX7lgbiiaJiIScQiVEEurt35hK8p6fQ2XNjjWhaJKISMgpVEIkITaBlH0p5Hke7l7h8pv2bCqYXrtTPRUROTQpVEKkaWxT8jyPR2c8SuQDkTR/rDkTlk4oc/n8w19xUXHqqYjIIUuhEiL5V9WPmT2GNg3bEBUexcsLXi5z+U17NtEgugHdErqppyIihyyFSojkh8rmtM1c0/saLu1xKdPXTyc9O73U5ZPTkmkZ15L2jdtroF5EDlkKlRDJDxWAC7pcwJlHnklmbibT1k/jsRmP8e26b4ssn7wnmVbxrWjfqD3rdq4jNy+3hlssInLgdPFjiOQ/U6Vtw7b0OqwXnZp2Ijo8mru+uovFWxaTEJvAspuW8cqCVzj6sKPZtGcTJ7Q5gQ6NO5Cdl82mPZto07BNLW+FiMj+UaiESLP6zTCM87ucj5kRGxnLKW1P4as1X9GlaRdW71jNUc8dxda9W+nYpCPJacm0imtFh8YdAFi9Y7VCRUQOOTr8FSJxUXF8dNlH/H3A3wvKzu98PpFhkUy4ZAJ3nXQXW/duZXCHwSSmJpKRk0HL+JZ0bNIRgNWpqwvqvbLgFe6fen+Nb4OIyP5STyWEzu9yfpH3Nx17E8N6DKNFXAuOPuxoru1zLc1im9HiiRakZ6fTMq4lbRq0ITIsksTUxIJ6o2eMZu2Otdze/3YaRDeo6c0QEam0kPZUzOxsM1tpZolmNrKU+WZmY4PzF5tZ34rqmlkTM/vSzFYFXxsHy5ua2TdmlmZm/wrldlVVeFg4LeJaAIE7GXdo3IH46Hgu7nYxAK3iWxEeFk6Hxh1YlboKgKTdSfyY8iPZedl8nvh5rbVdRKQyQhYqZhYOPAMMAboDl5tZ92KLDQE6BX9uAJ6rRN2RwBR37wRMCb4HyADuAf4Yqm0KlVuPv5WezXvSs3lPADo26VjQU5myZgoAUeFRfLTio9pqoohIpYSyp3IckOjua9w9C5gAXFBsmQuA1z1gFtDIzFpWUPcCYHxwejwwFMDd97r7dwTC5ZDSr1U/lvx+ScETIzs16URiaiLuzpS1U0iITeCKo65g0qpJZOdml6jv7pW6FYyISKiFMlQOBzYWep8ULKvMMuXVPczdkwGCr82rsc0HhY5NOrI3ey+b0zYzZe0UBrYbyNAuQ9mVuYtp66cVLOfuvDT/JRqPbszbS96uxRaLiASEMlRKe8pU8f9Ol7VMZepWiZndYGZzzWzutm3bqmOV1S7/DLCPVnzEpj2bGNR+ECcfcTIAi7YsKljur1P+yvWfXM+uzF1M3zC9VtoqIlJYKEMlCSh8oUVrYFMllymv7pbgITKCr1v3p1HuPs7d+7l7v2bNmu1P1RqTHyr3Tb2PqPAohnYdSpN6TWgU06jgVOPvNnzH6Bmjubb3tRzb6tgiZ4sVNitpFv3G9SMtK63G2i8idVcoQ2UO0MnM2ptZFHAZMLHYMhOB3wbPAusP7Aoe0iqv7kTgquD0VcDHIdyGWtG2UVsiwiLYsncLvz7q1xwWdxhmxpGNjyRxRyLZudlc/dHVtGvUjjFDxtC5aecyQ+XzxM+ZlzyPpVuX1vBWiEhdFLJQcfccYATwBbAceM/dl5nZcDMbHlxsErAGSAReBG4qr26wziPAGWa2Cjgj+B4AM1sHPAlcbWZJpZxtdkiICIugfaP2ANzR/46C8o5NOrI6dTWLtyxm9Y7VPDDwAeKi4ujYpCMbdm0gMyezxLqWb18OFL2YUkQkVEJ68aO7TyIQHIXLni807cDNla0bLE8BBpVRp90BNPegckaHM+jbsi9HHXZUQdmRjY/k3z/8m+9/+h6A/q37A4GwcZy1O9fy/U/f89WarwizMF4+/2VWbF8BBG77IiISarqi/iD1zK+eKVHWsUlHcj2Xj1Z+RIPoBrRvHOjNHNn4SABmbpzJ7yb+jtjIWPZm7+XmY2/mx5QfAco8PCYiUp10769DyJFNAuExZc0U+rToQ5gFfn35A/vPzHkGx3nrorcAeGvJW2TkBC7bWb1jNRk5Gby95G1d0yIiIaNQOYTkh0eu59K3ZcEdbUiITaBBdAPmJ8+nef3mnNflPNo2bMvri14HoFtCN1anrubVBa/y6w9/zcyNM0td//1T7+e6j68L/YaIyC+WQuUQ0jKuJfUi6gHQp0WfgnIzKwicIR2HEGZhnHzEyezI2AHArzr9ii17t/Dhig8BmLtpbol1Z+dmM2b2GMYvGs+ujF2h3hQR+YVSqBxCzKzgEFjhngpQJFSAgoslm8U247jDjwPgqzVfATB/8/wS6/567dek7ksl13OZsnbKfrdtVcoqrp94fcHhNhGpmxQqh5iOTToSExFDl4QuRcp7NOtBVHgUZx55JvBzqHRr1q0giABiI2OZt2leifW+/8P7xEfFEx8VX6W7IY+bN46XFrzEZ6s+2++6IvLLoVA5xNx2/G3886x/EhFW9MS9O0+4kwU3LqBxvcYAdG/WnRZxLejTok/B2WFhFsa1va9l+fbl7M3aW1A3LSuN/6z4D+d3OZ/BHQbzxeov9nsw//PVgSB6/4f3D2TzROQQp1A5xJzW7jSG9xteojwuKo7uzX6+1jPMwph7/VwePP1BGsY0JCE2gX6t+jG4w2DyPI/FWxYD8PL8l2n1RCtS96Xym16/4awjz2LDrg0F17cU9uHyD7nhkxu48ZMbyc3LLShP2p3E0q1LiYuK45MfP2Hb3m18nvi5zjITqYMUKr9ghzc4nLioOAAeHfwo/zj9HxzT6hgA5iUHDoE9OvNR2jduz/RrpnNWx7M4p9M5RIRFcNdXd7Ft7zZu//x2ZmyYwWsLX+Pi9y5mwtIJjJs/jnHzxhV8zheJXwBw/2n3k5aVRo9nezDkrSFVvsnlzI0z2ZO5p+D9iu0r+POXfybP86q0PhGpOQqVOuKaPtcwuMNgDo8/nOb1mzMveR5pWWmsSlnFxd0uLhiDadOwDU+c+QSf/PgJHZ/uyJjZYxjw2gCG/3c4A9sNJPWuVAa2G8jfvvkbKekpQODQV+sGrRlx3AgSYhPIyMkg3ML5as1XbN27lWs+voadGTsr1c6te7dyyquncO839xaUvb7odR6b+Rgrt6+s9v0iItVLoVLHmBn9W/fnuw3fsXjLYhwvcnoywC3H3cJvev2GxjGN+fI3X3Jhtwtp16gd717yLhFhETw95Gl2Zezi1NdO5eZPb+bD5R9yXufziAyP5JurvmHx7xfTr1U/pqydwvNzn+e1ha8V9GYqMmPDDPI8j/d+eK+gZ5J/KG5+8nxmbJjBMeOOIXlPcvXuGBGpFgqVOui0tqeRmJrIJys/AaBPy6KhYmaMHzqeNbetYXCHwbw/7H2W37ycZvUDjwro0bwHn1z+Cfuy9/Hs3Ge5rs91PHrGowD0bN6Tdo3aMaj9IGYnzeblBS8DsGDzgkq1Lf+Q2aY9m/huw3fAzzfFXLB5AROWTmB+8nz+9vXfSq3/6oJXixyaE5GapVCpgwa2HwjAC/NeoGm9phweX/yBnIFgyb8NTP77woZ0GsKym5ax7KZljDtvXMHYTb5BHQaR67ls2LUBw1i4eSEAGTkZPDD1AR6f+Xipbftuw3cc0/IY6kXU492l75Kdm11w37L5yfP5dv23hFkYry58lQXJRYMqOzebP375R+766q5SH7ssIqGnUKmDeh3Wiyb1mrAjYwd9WvYpERiVVS+yXpEzzgo7sc2JRIdHExsZy8XdL2bB5gWk7kul37h+3Pvtvdz99d0F4yz5Z4mlZaUxP3k+Z3c8m3M7n8v7P7zPypSV5OTl0CimEbN/ms3SrUv54wl/pEm9Jtw39b4in/nVmq9I3ZfKzoydBb2c0qSkpzDnpzlV2mYRKZ9CpQ4KszAGtB0AUGI8pbrERMRwfd/rubP/nZxyxCls3buVh6c/zLJtyxg1YBRZuVlMXDmRP03+E8eMO4bdmbuZlTSLXM/llCNOYVj3YWxL38bL8wOHz4Z1H0Z6djoAQ7sO5aqjr2LSqkmk7kst+MwJyybQMLoh0eHRTFw5kXu+vocrPriCnLycgmVy83I5951z6f9yf6atn3ZA27g7czc3fXoTP+3+qcJlf9r9Ex/88MEBfZ7IoUChUkcNbBc4BNa7Re+QfcbT5zzNA6c/UBBcY2aP4fjDj+feAfdyRMMjeOJ/T/DkrCdZsHkBv5v4O56a9RRhFsYJbU7g7I5nEx0ezbj5gfGRy3teDgTuCNCvVT+u7HUl2XnZvL8scLFlRk4G/1n+Hy7udjGDOgzi5QUv8+D0B3ln6Tvc8/U9BW16bu5zzEqaRYPoBlzxwRVsT9/Ovux99Hy2J2Nnjy1YbubGmfzlq7+wO3N3ie3akrYFgDcWvcFzc5/jts9vq3Bf3PvNvVzy/iVFHpY2ff10PTxNfnEUKnXUsB7DuKT7JZx15Fkh/6yjWxwNQHZeNlf3vhozY1j3YSzespjYyFhuO/423v/hfb5Y/QUPnf4QDaIbEB8dz+AOg0nPTufw+MM5oc0JhFs4Jx9xMpHhkfRu0Zvuzbrz5pI3AZi0ahJ7svZwWc/LOL/z+ezJ2kPvFr25tve1PDLjERo83IB6/6jHLZ/dwllHnsXXv/2abenbuOWzW3hp/kss27aMx2c+Tm5eLn/44g+c9MpJPDLjEU4ffzrb9m4r2JbXF71Oiyda8O7Sd3lt0WuEWzgfLP+AKWuK3i9t5saZBT2r3LxcJv4YeBr220veBmBB8gIGjh9I33F9+XL1lwAs2bKE8985v1I9H5GDlrvX2Z9jjjnGpWZ0HNvRox+I9tT0VHd3n/PTHGcUft+393lObo6PmTXGF21eVKTOS/Neckbhg18f7O7uT8x8wr9e83XB/H9M+4czCv9x+48+7L1h3uzRZp6dm+3b9273i969yJdvW+77svf5A1Mf8Ns/u93/NPlPft+39/mWtC3u7n7ft/c5o/AGDzfwJqObOKPwGz+50RmF/+7j3/m7S9/1mAdj/Ih/HuEzNszw7Xu3e9PRTZ1RFCw/+rvR3v6p9t72n209MSXR8/Ly/K9f/dUZhQ8aP8gzsjN86rqpzii8/j/qe5enu3hWTpb3fr63t3i8hR/17FEecX+ET1s3zU9+5WRnFH75vy+vod+KSNUAc72Mv6vmdfhWGv369fO5c0veBl6q35hZY0jPTucvp/yloGzOT3Po07JPifuY5du2dxstnmjBiGNHMGbImBLzk/ck035Me4Z2HcrElRO5pvc1pT4xsyyZOZn0fqE3K7av4NMrPuW6idexOW0zPZv3ZP4N84kMj2TOT3O47IPLWLNjDQ2jG7I3ey/PnPMMN/73RiLDItn0h02s37meM988k3ALp1V8KxZtWcSAtgOYun4qF3W7iCYxTXh98es8dPpD/PHLP3Lc4cfx/U/f8+H/fcjp7U/n2BePZdOeTezN3kvfln2Znzyf0YNHExsZy/V9ryc6IrrMbcjzvCJn6e2P9Ox0DKNeZD2env00aVlpRX4/ImUxs3nu3q/UmWWlTV34UU/l4PfV6q980+5NZc4f8ekIZxTOKHzaumn7vf5lW5f52FljPS8vz/825W/OKHz6+ulFltm5b6c/PuNxv+S9S/xfs//l7u5/mvwn//PkPxdZz2mvneZnvXGWP/rdo56Xl+dPznzSbZQ5o/Bz3jrHU9JTPPqBaG/wcAN/9vtnC+ouSF7g0Q9Ee49neviezD3e/qn2Bdv03JznPCM7wx+b8Zg/9b+nivTmVqWs8sMeO8zvnnK35+XllbmNKekpnpWT5e7uuzN2+77sfb5p9yY/4p9H+OnjT/c9mXs87qE4ZxQ+c8PM/d6HNWFy4mRP2pVU282QIMrpqdT6H/ba/FGoHPo27troUQ9EeesnW3tuXu4BrWtf9j5fmLywmloW8L+N//OBrw30yYmT3d19yZYlBYffCluYvLDgj+aWtC2+bOsy7/tCX+/2r27+wNQHCkIm9h+xvnTLUs/Ny/UBrw4oCK07Pr/D0zLT3N09Ly/PZyfN9hkbZviz3z/rsf+I9eNfPN6nrpvqzR9r7s0fa+5d/9W1YJ3XT7zeGYXHPxTvvZ/v7dm52Z6Vk+UvzH3Bk3Yl+YadG/xXb/3K7/363lLb/u9l//ZOYzv59r3b3d09Ozfbn5vznE9dN7XIcqnpqb5kyxLfsW/Hfu3DpF1JHnZfmJ/79rn7VU9Cp7xQ0eEvHf465L228DUaRjfkwm4X1nZTqtX4heO5+uOrCbMwhnYdyujBozn5lZNpGNOQ3i16896y9xh37jgWbF7Ac3Ofo3n95pza9lQ27NrA9z99X7CeE9ucyJyf5pCdl83h8YfTJaEL09ZPY/zQ8YyYNIIdGTvomtCV+0+7n//79//xm16/wXHeXPwmTes1pV5kPbanbycjJ4OIsAjO6XQOJ7U5iZOPOJkT25xI/5f6M/un2dx9yt38ru/vGPb+MOZumkuTek1YfvNymtdvztR1UznrzbPIzM0kITaBCRdPYFCHQZXaD6O/G83IKSMBWPL7JfRs3hOArNwsosKjAPhh2w+MnT2WPi36cGO/G7n1s1tZs2MNr1/4Ok3qNQECJ0z86cs/sWHXBt4f9n6Vr89atHkRcVFxRZ5TVFXZudnM2DiDrgldaRHX4oDXV1PKO/ylUFGoyEEqIyeDI/55BGlZaSy/eTltG7Xl23XfcuYbZ1I/qj6X9biMZ3/1LGbGdxu+44n/PcHybcsJDwtnxLEjaNuoLRB4Gujk1ZN5Zs4zjDl7DO0btyc9O53YyFjunnI3D333EI+f8Th3nnAn/5j+D+75JnAK9m3H38bU9VPZtGcTX1z5BTERMbw0/yXeXfYuSbuTMIxnznmGmybdRKOYRuTk5XBY/cNI2ZfCPafew1+m/IULu17IOxe/w8mvnsyGXRt4ZNAjPPTdQ6zYvoKvf/s1nZt25py3z6Fvi77cevytHN3iaNydvdl7iYuKw93p/mx3osOjWZW6irM7ns3QLkN5cf6LTN8wna4JXcnIyWDdznUA1Iuox+TfTObUV0/FcTo37cx9p93H4fGH8+SsJ/loxUcATLpiEkM6BZ6Smud5TFw5kR+2/cAfTvhDqWNYy7YuY86mOXy99mveWPwGzWKbMft3szmi4RH86/t/MWb2GMadN47BHQZX+vf76Y+fcs3H17AtfRvNYpvx3yv+W/CU1sJS0lPYuncrmbmZABhGh8YdiI+Or/RnVTeFShkUKnKw+yLxC7Jyszivy3kFZbszdxMXFVflAfrCUvel8vD0h/nbqX+jYUxDIHDa9Na9W/nDCX8gz/PIzM0kNjK2SL3t6ds57sXjWLtzLVHhUUy+cjKnjT+N2MhYpvx2Cv1b9+fBaQ9yzzf3cHbHs/k88XOePedZfn/s79mTuYeuz3Slc9POHH3Y0fzr+38RExFDVm4Wj57xKBOWTuD7n77nxDYn0rN5T16Y9wIvnvciS7YsYez3gWuJ2jZsyyXdL+HHlB+JjojmxNYncnzr4znl1VOIi4ojMyeTty9+mzu+uIMNuzYAEG7hPDzoYZ7+/mnaNWrHN1d9wwfLP+DBaQ+yZOsSINCr+/ewf5MQm8CY2WNISU8hZV8KL81/CceJCo9i+DHDeWPxG8RHx2MY63etJzYylvioeMYPHc+bS94kNy+XBtENaBDdgIbRDVm/az2f/PgJA9sN5MmznmRz2mZOfuVkOjXtxB3972DUt6PYnLaZp4c8zYB2A1i0eRFnHnkmL8x7gT9/+Wecon+nW8S1YPo102levznZudk0jW1a4nebk5fDzI0zeWn+Syzfvpw/n/hnLul+CWZGSnoKe7L20K5Ruyp9bxQqZVCoiFTd1HVTOW38aVza41ImXDKBNxe/SccmHenfuj8QONz01yl/5dGZj9K6QWsSb0ks6AU8Nesp7vjiDiLCIriy15U8ceYTDHt/GF+v/Zr4qHiu63Md0zdMZ9GWwKGmdbetI8zC+HLNl3Rs0pHuzbqXetbglR9eyVtL3mL4McN57tznyPM8pq+fTuq+VE5rdxqN6zXm6dlPc+vnt9IgugG7M3fTNaErd59yNxFhEVz78bVEhkfSuWln5m6aS0RYBHmex4hjR3DL8bfQKr4VsZGxfLvuW67+6Gp6t+jNlb2upEvTLhz74rFk5mbSKKYRCbEJ7M7cza6MXWTmZlI/sj6ntz+dL1YH/pMA0LpBa77/3fe0jG/J1r1bueKDK5iy9ufrnWIjY0nPTueibhcxrPswYiJicHf25ezj1s9uJTI8krSsNLJzs3l40MPUi6zH6tTVBY+2mLx6MjsydhAfFU/L+Jb8mPIjTes1pUm9JqxKXcVlPS/jnYvfqdLvXqFSBoWKyIH5eu3XdEvoRsv4lmUuM3Xd1IJxoHx7s/bSfkx7UvelsmLECjo26UhWbhYvznuRszqeRccmHYHAIcCMnAwaxTSqVHtWp67mhv/ewCvnv1Jw+K+49Ox0rvjgChJiEzi387mc1/k8wsPCAfgx5Udu+ewWpq+fzrjzxnFpj0vZm723Up//n+X/YcnWJdx2/G0FvT4InLpuZkSFR7Fi+wo+XP4hOXk5XN7zcjo17VSwXG5eLq8ufJW9WXvp3qw7ryx8hTYN2vDwoIcL2pdv7qa5XPLeJZzS9hRS0lP4LPEzACLDIsnOy6ZFXAvO7ng2QzoO4ZxO5xATEcNbi99i5saZbEvfxrGtjmVwh8Ece/ixldqvxSlUyqBQEak9E1dOZNOeTaU+Hru2ZeZklnt90MHE3Zmydgqt4lvRLaEbOzN20jCmYbUcHi2LQqUMChURkf1XXqjo3l8iIlJtFCoiIlJtFCoiIlJtFCoiIlJtFCoiIlJtFCoiIlJtFCoiIlJtFCoiIlJt6vTFj2a2DVhfhaoJwPZqbk51ULv238HaNrVr/xys7YKDt20H0q627t6stBl1OlSqyszmlnU1aW1Su/bfwdo2tWv/HKztgoO3baFqlw5/iYhItVGoiIhItVGoVM242m5AGdSu/Xewtk3t2j8Ha7vg4G1bSNqlMRUREak26qmIiEi1UaiIiEi1UajsBzM728xWmlmimY2s5ba0MbNvzGy5mS0zs9uC5aPM7CczWxj8OacW2rbOzJYEP39usKyJmX1pZquCr41ruE1dCu2ThWa228xur639ZWavmNlWM1taqKzMfWRmfwl+71aa2Vk13K7HzGyFmS02s/+YWaNgeTsz21do3z1fw+0q83dXy/vr3UJtWmdmC4PlNbm/yvr7EPrvmLvrpxI/QDiwGugARAGLgO612J6WQN/gdDzwI9AdGAX8sZb31TogoVjZo8DI4PRIYHQt/y43A21ra38BpwJ9gaUV7aPg73UREA20D34Pw2uwXWcCEcHp0YXa1a7wcrWwv0r93dX2/io2/wng3lrYX2X9fQj5d0w9lco7Dkh09zXungVMAC6orca4e7K7zw9O7wGWA4fXVnsq4QJgfHB6PDC09prCIGC1u1flbgrVwt2nAanFisvaRxcAE9w9093XAokEvo810i53n+zuOcG3s4DWofjs/W1XOWp1f+UzMwP+D3gnFJ9dnnL+PoT8O6ZQqbzDgY2F3idxkPwRN7N2QB9gdrBoRPBQxSs1fZgpyIHJZjbPzG4Ilh3m7skQ+MIDzWuhXfkuo+g/9NreX/nK2kcH03fvWuCzQu/bm9kCM5tqZqfUQntK+90dLPvrFGCLu68qVFbj+6vY34eQf8cUKpVnpZTV+vnYZhYHfADc7u67geeAI4HeQDKB7ndNO8nd+wJDgJvN7NRaaEOpzCwKOB94P1h0MOyvihwU3z0zuxvIAd4KFiUDR7h7H+BO4G0za1CDTSrrd3dQ7C/gcor+56XG91cpfx/KXLSUsirtM4VK5SUBbQq9bw1sqqW2AGBmkQS+MG+5+4cA7r7F3XPdPQ94kRB1+8vj7puCr1uB/wTbsMXMWgbb3RLYWtPtChoCzHf3LcE21vr+KqSsfVTr3z0zuwo4F/i1Bw/CBw+VpASn5xE4Dt+5ptpUzu/uYNhfEcBFwLv5ZTW9v0r7+0ANfMcUKpU3B+hkZu2D/9u9DJhYW40JHq99GVju7k8WKm9ZaLELgaXF64a4XfXNLD5/msAg71IC++qq4GJXAR/XZLsKKfK/x9reX8WUtY8mApeZWbSZtQc6Ad/XVKPM7GzgLuB8d08vVN7MzMKD0x2C7VpTg+0q63dXq/sraDCwwt2T8gtqcn+V9feBmviO1cSZCL+UH+AcAmdRrAburuW2nEyge7oYWBj8OQd4A1gSLJ8ItKzhdnUgcBbJImBZ/n4CmgJTgFXB1ya1sM9igRSgYaGyWtlfBIItGcgm8L/E68rbR8Ddwe/dSmBIDbcrkcDx9vzv2fPBZS8O/o4XAfOB82q4XWX+7mpzfwXLXwOGF1u2JvdXWX8fQv4d021aRESk2ujwl4iIVBuFioiIVBuFioiIVBuFioiIVBuFioiIVBuFikg1MbO04Gs7M7uimtf912LvZ1bn+kWqi0JFpPq1A/YrVPIviitHkVBx9xP3s00iNUKhIlL9HgFOCT4z4w4zCw8+k2RO8OaHNwKY2WnBZ168TeAiPszso+CNOJfl34zTzB4B6gXX91awLL9XZMF1L7XAM2wuLbTub83s3xZ4FspbwausRUIqorYbIPILNJLAcz7OBQiGwy53P9bMooEZZjY5uOxxQE8P3G4c4Fp3TzWzesAcM/vA3Uea2Qh3713KZ11E4IaKRwMJwTrTgvP6AD0I3MNpBnAS8F11b6xIYeqpiITemcBvLfAEwNkEbpXRKTjv+0KBAnCrmS0i8NySNoWWK8vJwDseuLHiFmAqcGyhdSd54IaLCwkclhMJKfVURELPgFvc/YsihWanAXuLvR8MnODu6Wb2LRBTiXWXJbPQdC769y41QD0Vkeq3h8AjXPN9Afw+eCtyzKxz8A7OxTUEdgQDpSvQv9C87Pz6xUwDLg2O2zQj8Hjbmr4jr0gB/c9FpPotBnKCh7FeA8YQOPQ0PzhYvo3SH6f8OTDczBYTuFPsrELzxgGLzWy+u/+6UPl/gBMI3PnWgT+7++ZgKInUON2lWEREqo0Of4mISLVRqIiISLVRqIiISLVRqIiISLVRqIiISLVRqIiISLVRqIiISLX5fwqp7FTCKca6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(iters,y_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
